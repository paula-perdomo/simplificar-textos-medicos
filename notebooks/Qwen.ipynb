{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-z8bgVJ5vaM5",
    "outputId": "60c3d970-0984-438f-9859-bed7263a6088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: triton in /usr/local/lib/python3.12/dist-packages (3.5.0)\n",
      "Collecting triton\n",
      "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
      "Collecting trl\n",
      "  Downloading trl-0.25.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting textstat\n",
      "  Downloading textstat-0.7.11-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score) (3.10.0)\n",
      "Collecting pyphen (from textstat)\n",
      "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from textstat) (3.9.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from textstat) (75.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (3.2.5)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (1.5.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Downloading transformers-4.57.2-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m140.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.25.1-py3-none-any.whl (465 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m465.5/465.5 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading textstat-0.7.11-py3-none-any.whl (176 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m138.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m155.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyphen, pyarrow, numpy, textstat, pandas, transformers, datasets, bitsandbytes, accelerate, trl, bert-score\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 18.1.0\n",
      "    Uninstalling pyarrow-18.1.0:\n",
      "      Successfully uninstalled pyarrow-18.1.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.57.1\n",
      "    Uninstalling transformers-4.57.1:\n",
      "      Successfully uninstalled transformers-4.57.1\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.0.0\n",
      "    Uninstalling datasets-4.0.0:\n",
      "      Successfully uninstalled datasets-4.0.0\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.11.0\n",
      "    Uninstalling accelerate-1.11.0:\n",
      "      Successfully uninstalled accelerate-1.11.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.12.0 bert-score-0.3.13 bitsandbytes-0.48.2 datasets-4.4.1 numpy-2.3.5 pandas-2.3.3 pyarrow-22.0.0 pyphen-0.17.2 textstat-0.7.11 transformers-4.57.2 trl-0.25.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "1255272b3524480a85b7a332ff365917",
       "pip_warning": {
        "packages": [
         "accelerate",
         "numpy",
         "pandas",
         "pyarrow",
         "transformers"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -U torch --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -U transformers accelerate datasets bitsandbytes triton peft trl \\\n",
    "    bert-score textstat numpy pandas\n",
    "# ===============================\n",
    "# âœ… LIMPIEZA DE SALIDA Y VERIFICACIÃ“N DE VERSIONES\n",
    "# ===============================\n",
    "import IPython\n",
    "IPython.display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRrMzS8HvdET",
    "outputId": "8bf1b360-b7a3-4b59-b46e-71b009890ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXpze8E_wThQ",
    "outputId": "8e4e23e0-f835-42d8-f2d6-9f4770324f20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/cochrane_data\n",
      "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
      "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
      "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
      "\u001b[33mhint: \u001b[m\n",
      "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
      "\u001b[33mhint: \u001b[m\n",
      "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
      "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
      "\u001b[33mhint: \u001b[m\n",
      "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
      "Initialized empty Git repository in /content/cochrane_data/.git/\n",
      "Updating origin\n",
      "remote: Enumerating objects: 72074, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 72074 (delta 0), reused 2 (delta 0), pack-reused 72071 (from 2)\u001b[K\n",
      "Receiving objects: 100% (72074/72074), 315.90 MiB | 33.61 MiB/s, done.\n",
      "Resolving deltas: 100% (2991/2991), done.\n",
      "From https://github.com/feliperussi/bridging-the-gap-in-health-literacy\n",
      " * [new branch]          felipe     -> origin/felipe\n",
      " * [new branch]          main       -> origin/main\n",
      "From https://github.com/feliperussi/bridging-the-gap-in-health-literacy\n",
      " * branch                main       -> FETCH_HEAD\n",
      "Updating files: 100% (47359/47359), done.\n"
     ]
    }
   ],
   "source": [
    "# 1. Crear carpeta y entrar\n",
    "!mkdir cochrane_data\n",
    "%cd cochrane_data\n",
    "\n",
    "# 2. Inicializar git vacÃ­o\n",
    "!git init\n",
    "\n",
    "# 3. Agregar remote\n",
    "!git remote add -f origin https://github.com/feliperussi/bridging-the-gap-in-health-literacy.git\n",
    "\n",
    "# 4. Activar modo sparse checkout\n",
    "!git config core.sparseCheckout true\n",
    "\n",
    "# 5. Indicar SOLO las carpetas que queremos\n",
    "!echo \"data_collection_and_processing/Data Sources/Cochrane/train/pls\" >> .git/info/sparse-checkout\n",
    "!echo \"data_collection_and_processing/Data Sources/Cochrane/train/non_pls\" >> .git/info/sparse-checkout\n",
    "\n",
    "# 6. Descargar solo esa parte del repo\n",
    "!git pull origin main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wHQsOKEp71PS",
    "outputId": "700776e1-af97-4f8c-9477-d606cb9f5e46"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rR-_bl3p73M0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import glob, pandas as pd\n",
    "import transformers, trl, peft, accelerate, datasets\n",
    "import bitsandbytes as bnb\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "fnLnyECi74jE",
    "outputId": "f6c534e2-4c3c-441b-b034-b6d8c30bd84f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Total PLS (sin accumulated): 4797\n",
      "ğŸ“‚ Total non-PLS (sin accumulated): 7251\n",
      "\n",
      "âœ… Emparejados 2000 pares por nombre base (sin 'accumulated' en ninguno)\n",
      "ğŸ’¾ Guardado en: cochrane_pairs_clean.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"10.1002-14651858.CD009400\",\n          \"10.1002-14651858.CD003079\",\n          \"10.1002-14651858.CD007561\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_pls\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"10.1002-14651858.CD009400.pub2-pls.txt_section3.txt\",\n          \"10.1002-14651858.CD003079.pub4-pls.txt\",\n          \"10.1002-14651858.CD007561.pub3-pls.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_non_pls\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"10.1002-14651858.CD009400.pub2-abstract.txt_section12.txt\",\n          \"10.1002-14651858.CD003079.pub4-abstract.txt\",\n          \"10.1002-14651858.CD007561.pub3-abstract.txt_section13.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pls\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"The purpose of this systematic review was to examine the effectiveness and safety of helminth therapy for inducing remission in people with IBD. This review identified two randomised controlled trials including a total of 90 participants. One study compared twice weekly treatment with helminths (an 0.8 mL solution containing 2500 live eggs of the helminth Trichuris suis) for 12 weeks to a matching placebo (an 0.8 ml identical looking solution with no Trichuris suis eggs) in 54 patients with active ulcerative colitis. Few remissions occurred during the trial and helminth treatment had no detectable effect on these remissions. Ten per cent (3/30) of patients in the helminth group achieved remission compared to four per cent (1/24) of placebo patients. A higher proportion of patients in the helminth group (43% or 13/30) improved clinically compared to the placebo group (17% or 4/24). However, this difference could be a chance effect. We could not determine whether the proportion of patients who had a side effect was higher in either group. No observed side effects were thought to be related to treatment were reported in this study. The other study compared one treatment with various doses of helminths (a solution of 500, 2500 or 7500 Trichuris suis eggs) to a matching placebo in 36 patients with Crohn's disease. This study was designed to assess side effects and did not measure clinical remission or improvement. There amount of information available on side\\u2010effects at two weeks was limited and the results were uncertain due to the small number of participants in the study. The only side effect that was judged to be possibly related to the study treatment was dysgeusia (a distortion of the sense of taste). This was reported in one patient in the helminth group and in one patient in the placebo group. Currently, there is insufficient evidence to allow any firm conclusions regarding the effectiveness and safety of helminths used to treat patients with IBD. The only information available relating to clinical improvement in patients with active ulcerative colitis comes from one small study. We do not know how safe helminths are when used in patients with ulcerative colitis and Crohn's disease. Further randomised controlled trials are required to assess the efficacy and safety of helminth therapy in IBD.\",\n          \"Benzodiazepines alone or in combination with antipsychotic drugs for acute psychosis\\nReview question \\nThe aim of this review was to compare the tranquillising (calming) or sedative (sleepiness) effects of benzodiazepines, given alone or combined with other drugs compared with the effect of placebo (a pretend treatment), other drugs or non\\u2010drug treatments for people who are aggressive or agitated because they are experiencing psychoses. \\nBackground \\nAcute psychosis is a rapid worsening of a person\\u2019s mental state where touch with reality is often lost. People may experience frightening delusions or hallucinations which are distressing and may cause agitated or aggressive behaviour. In urgent cases, this agitation or aggression may cause harm to the person experiencing the psychoses or others around them. To avoid such harm, rapid tranquillisation or sedation with medicines may be required. The most common medicines used to achieve a state of calmness or sedation are benzodiazepines and these can be given either alone or in combination with antipsychotics. \\nSearching \\nThe original search for this review was carried out in January 2012 and subsequently two further update searches were run in August 2015 and August 2016. In total, these searches found 2497 records, which the review authors checked for inclusion or exclusion from the review. Authors included records only if they were randomised trials (clinical studies where people are randomly put into one of two or more treatment groups) that allocated people with acute psychosis who presented with agitation, violence aggressive behaviour (or a combination of these) to receive benzodiazepines either given alone or combined with any antipsychotics, versus placebo, antipsychotics alone or in combination with other antipsychotics/benzodiazepines/antihistamines or non\\u2010drug treatments. \\nEvidence found \\nIn total, 20 trials were included. Overall, the quality of evidence was low or very low due to serious risk of bias and very small size of included trials. There was no clear difference in improvement between benzodiazepines and placebo, benzodiazepines and antipsychotics or benzodiazepines plus antipsychotics and benzodiazepines alone or antipsychotic alone. When benzodiazepines were compared with combined antipsychotics/antihistamines, there was a higher risk of no improvement in people receiving benzodiazepine alone but the evidence was of low quality. Only one study showed lower effect of combined benzodiazepines/antipsychotics versus combined antihistamines/antipsychotics. However, the evidence was of very low quality. In terms of side effects, people receiving benzodiazepines compared to antipsychotics had lower risk of presenting with symptoms such as shaking, tremors and slurred speech whereas the results for the sedation caused were unclear. \\nConclusions \\nThe existing trials are not informative enough to support or refute the use of benzodiazepines alone or in additional to other medicines when urgent tranquillisation or sedation with medicines is required. Although benzodiazepines alone may cause fewer side effects compared to older antipsychotics, when they are added on to other medicines this may lead to unnecessary side effects. Further studies are needed to provide good\\u2010quality evidence with robust conclusions to inform clinical practice and policies around rapid tranquillisation for people with psychoses who are aggressive or agitated.\",\n          \"Effectiveness of angioplasty compared with stenting in atherosclerotic disease of the iliac arteries \\nBackground \\nAtherosclerosis in the iliac artery (main pelvic artery towards the leg) may result in narrowing or obstruction (occlusion), leading to reduced blood flow to the leg. This is called iliac artery occlusive disease. Iliac artery occlusive disease may lead to symptoms of pain in the legs when walking (intermittent claudication), pain at rest, or ulcers of the foot or leg. A range of surgical and endovascular (from inside the artery, e.g. angioplasty) treatment options are available. Open surgical procedures have excellent patency rates (percentage of the vessels that remain open) but at the cost of substantial illness and death. Endovascular treatment has good safety and short\\u2010term effectiveness with decreased illness, complications and costs compared with open surgical procedures. Percutaneous transluminal angioplasty (PTA; dilation of the artery with a balloon) and stenting (insertion of a small mesh tube) are widely used endovascular treatment options for iliac artery occlusive disease. A narrowing or obstruction of the iliac artery can be treated successfully by PTA alone. If PTA alone is not successful, an additional stent can be placed. Alternatively, a stent could be placed on its own to treat an iliac narrowing or obstruction (this is called primary stenting (PS)). However, there is limited evidence to prove which endovascular treatment strategy is better for lesions that restrict the iliac arteries. This review investigates whether it is better to place a stent in the first instance, or only under particular circumstances. \\nStudy characteristics and key results \\nWe found no new studies for this update. Previously, we had identified two studies with a combined total of 397 participants relevant to this topic. Combining the data was not possible due to the differences between the two included studies. The evidence in this Cochrane Review is current to 24 September 2019. \\nFor the following outcomes of interest, no clear differences emerged between the two types of treatment: technical success of the procedure, improvement in the severity of the arterial occlusive disease, or patency of the treated vessel. However, in one study, which only included iliac artery occlusions, fewer complications were observed in the group of participants treated with PS. Neither study reported on delayed complications. One study reported on reintervention, and resolution of symptoms and signs, with no evidence of a difference detected between the PS group and the PTA group. Neither study reported on improvement in walking distance. More research on this subject is necessary. \\nReliability of the evidence \\nBoth studies had some risk of bias relating to selective reporting and non\\u2010blinding of participants and personnel. Both studies occurred in the 1990s and techniques have since evolved. We considered the overall certainty of the evidence to be low due to this risk of bias, the small number of included studies and the differences in the types of patients that were included.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"non_pls\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"Two RCTs (90 participants) were included. One trial assessed the efficacy and safety of Trichuris suis (T. suis) ova in patients with UC (n = 54). The other RCT was a phase one that assessed the safety and tolerability of T. suis ova in patients with CD (n = 36). The risk of bias in both studies was judged to be low. In the UC study, during the 12\\u2010week study period, participants in the active arm received 2\\u2010weekly aliquots of 2500 T. suis eggs, added to 0.8 mL of saline; those in the placebo arm received 0.8 mL saline only. There were sparse data available for the outcomes clinical remission and clinical improvement. Ten per cent (3/30) of patients in the T. suis arm entered remission compared to 4% (1/24) of patients in the placebo arm (RR 2.40, 95% CI 0.27 to 21.63). Forty\\u2010three per cent (13/30) of patients in the T. suis group achieved clinical improvement compared to 17% (4/24) of placebo patients (RR 2.60, 95% CI 0.97 to 6.95). The mean ulcerative colitis disease activity index (UCDAI) score was lower in the T. suis group (6.1 +/\\u2010 0.61) compared to the placebo group (7.5 +/\\u2010 0.66) after 12 weeks of treatment (MD \\u20101.40, 95% CI \\u20101.75 to \\u20101.05). There was only limited evidence relating to the proportion of patients who experienced an adverse event. Three per cent (1/30) of patients in the T. suis group experienced at least one adverse event compared to 12% (3/24) of placebo patients (RR 0.27, 95% CI 0.03 to 2.40). None of the adverse events reported in this study were judged to be related to the study treatment. GRADE analyses rated the overall quality of the evidence for the primary and secondary outcomes (i.e. clinical remission and improvement) as low due to serious imprecision. In the CD study, participants received a single treatment of T. suis ova at a dosage of 500 (n = 9), 2500 (n = 9), or 7500 (n = 9) embryonated eggs or matching placebo (n = 9). The CD study did not assess clinical remission or improvement as outcomes. There were sparse data on adverse events at two weeks. Thirty\\u2010seven per cent (10/27) of patients in the T. suis group experienced at least one adverse event compared to 44% (4/9) of placebo patients (RR 0.83, 95% CI 0.35 to 2.01). Only one adverse event (dysgeusia) was judged to be possibly related to treatment in this study. Dysgeusia was reported in one patient in the T. suis group and in one patient in the placebo group.\",\n          \"Background\\nAcute psychotic illness, especially when associated with agitated or violent behaviour, can require urgent pharmacological tranquillisation or sedation. In several countries, clinicians often use benzodiazepines (either alone or in combination with antipsychotics) for this outcome. \\nObjectives\\nTo examine whether benzodiazepines, alone or in combination with other pharmacological agents, is an effective treatment for psychosis\\u2010induced aggression or agitation when compared with placebo, other pharmacological agents (alone or in combination) or non\\u2010pharmacological approaches. \\nSearch methods\\nWe searched the Cochrane Schizophrenia Group's register (January 2012, 20 August 2015 and 3 August 2016), inspected reference lists of included and excluded studies, and contacted authors of relevant studies. \\nSelection criteria\\nWe included all randomised controlled trials (RCTs) comparing benzodiazepines alone or in combination with any antipsychotics, versus antipsychotics alone or in combination with any other antipsychotics, benzodiazepines or antihistamines, for people who were aggressive or agitated due to psychosis. \\nData collection and analysis\\nWe reliably selected studies, quality assessed them and extracted data. For binary outcomes, we calculated standard estimates of risk ratio (RR) and their 95% confidence intervals (CI) using a fixed\\u2010effect model. For continuous outcomes, we calculated the mean difference (MD) between groups. If there was heterogeneity, this was explored using a random\\u2010effects model. We assessed risk of bias and created a 'Summary of findings' table using GRADE. \\nMain results\\nTwenty trials including 695 participants are now included in the review. The trials compared benzodiazepines or benzodiazepines plus an antipsychotic with placebo, antipsychotics, antihistamines, or a combination of these. The quality of evidence for the main outcomes was low or very low due to very small sample size of included studies and serious risk of bias (randomisation, allocation concealment and blinding were not well conducted in the included trials, 30% of trials (six out of 20) were supported by pharmaceutical institutes). There was no clear effect for most outcomes. \\nBenzodiazepines versus placebo\\nOne trial compared benzodiazepines with placebo. There was no difference in the number of participants sedated at 24 hours (very low quality evidence). However, for the outcome of global state, clearly more people receiving placebo showed no improvement in the medium term (one to\\u00a048 hours) (n = 102, 1 RCT, RR 0.62, 95% CI 0.40 to 0.97, very low quality evidence).  Benzodiazepines versus antipsychotics \\nWhen compared with haloperidol, there was no observed effect for benzodiazepines for sedation by 16 hours (n = 434, 8 RCTs, RR 1.13, 95% CI 0.83 to 1.54, low quality evidence). There was no difference in the number of participants who had not improved in the medium term (n = 188, 5 RCTs, RR 0.89, 95% CI 0.71 to 1.11, low quality evidence). However, one small study found fewer participants improved when receiving benzodiazepines compared with olanzapine (n = 150, 1 RCT, RR 1.84, 95% CI 1.06 to 3.18, very low quality evidence). People receiving benzodiazepines were less likely to experience\\u00a0extrapyramidal\\u00a0effects in the medium term compared to people receiving haloperidol (n = 233, 6 RCTs, RR 0.13, 95% CI 0.04 to 0.41, low quality evidence). \\nBenzodiazepines versus combined antipsychotics/antihistamines\\nWhen benzodiazepine was compared with combined antipsychotics/antihistamines (haloperidol plus promethazine), there was a higher risk of no improvement in people receiving benzodiazepines in the medium term (n = 200, 1 RCT, RR 2.17, 95% CI 1.16 to 4.05, low quality evidence). However, for sedation, the results were controversial between two groups: lorazepam may lead to lower risk of sedation than combined antipsychotics/antihistamines (n = 200, 1 RCT, RR 0.91, 95% CI 0.84 to 0.98, low quality evidence); while, midazolam may lead to higher risk of sedation than combined antipsychotics/antihistamines (n = 200, 1 RCT, RR 1.13, 95% CI 1.04 to 1.23, low quality evidence). \\nOther combinations\\nData comparing benzodiazepines plus antipsychotics versus benzodiazepines alone did not yield any results with clear differences; all were very low quality evidence. When comparing combined benzodiazepines/antipsychotics (all studies compared haloperidol) with the same antipsychotics alone (haloperidol), there was no difference between groups in improvement in the medium term (n = 185, 4\\u00a0RCTs, RR 1.17, 95% CI 0.93 to 1.46, low quality evidence), but sedation was more likely in people who received the combination therapy (n = 172, 3\\u00a0RCTs, RR 1.75, 95% CI 1.14 to 2.67,very low quality evidence). Only one study compared combined benzodiazepine/antipsychotics with antipsychotics; however, this study did not report our primary outcomes. One small study compared combined benzodiazepines/antipsychotics with combined antihistamines/antipsychotics. Results showed a higher risk of no clinical improvement (n = 60, 1 RCT, RR 25.00, 95% CI 1.55 to 403.99, very low quality evidence) and sedation status (n = 60, 1 RCT, RR 12.00, 95% CI 1.66 to 86.59, very low quality evidence) in the combined benzodiazepines/antipsychotics group. \\nAuthors' conclusions\\nThe evidence from RCTs for the use of benzodiazepines alone is not good. There were relatively few good data. Most trials were too small to highlight differences in either positive or negative effects. Adding a benzodiazepine to other drugs does not seem to confer clear advantage and has potential for adding unnecessary adverse effects. Sole use of older antipsychotics unaccompanied by anticholinergic drugs seems difficult to justify. Much more high\\u2010quality research is still needed in this area.\",\n          \"There was no evidence of a difference following percutaneous transluminal angioplasty (PTA) with selective stenting compared to primary stenting (PS) in technical success rates in either the study involving stenotic lesions (odds ratio (OR) 1.51, 95% confidence interval (CI) 0.77 to 2.99; 279 participants; low certainty evidence); or the study involving iliac artery occlusions (OR 2.95, 95% CI 0.12 to 73.90; 112 participants; low certainty evidence). In one trial, PTA of iliac artery occlusions resulted in a higher rate of major complications, especially distal embolisation (OR 4.50 95% CI 1.18 to 17.14; 1 study, 112 participants; low certainty evidence). Immediate complications were similar in the second study (OR 1.81, 95% CI 0.64 to 5.13; 1 study, 279 participants; low certainty evidence). Neither study reported on delayed complications. No evidence of a difference was seen in symptomatic improvement (OR 1.03, 95% CI 0.47 to 2.27; 1 study, 157 participants; low certainty evidence). The second study did not provide data but reported no differences. For the outcome of patency, no evidence of a difference was seen in the study involving iliac occlusion at two years (OR 1.60, 95% CI 0.34 to 7.44; 1 study, 57 participants; low certainty evidence); or the study involving stenotic lesions at two years (71.3% in the PS group versus 69.9% in the PTA group). Only one study reported on reintervention (six to eight years, OR 1.22, 95% CI 0.67 to 2.23; 1 study, 279 participants; low certainty evidence); and resolution of symptoms and signs (12 months, OR 1.14, 95% CI 0.65 to 2.00; 1 study, 219 participants; low certainty evidence), with no evidence of a difference detected in either outcome. Neither study reported on improvement in walking distance as reported by the patient.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-04fa4cec-67f2-40f1-bea2-afd77c930217\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_pls</th>\n",
       "      <th>file_non_pls</th>\n",
       "      <th>pls</th>\n",
       "      <th>non_pls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1002-14651858.CD000006</td>\n",
       "      <td>10.1002-14651858.CD000006.pub2-pls.txt</td>\n",
       "      <td>10.1002-14651858.CD000006.pub2-abstract.txt</td>\n",
       "      <td>Absorbable stitches for repair of episiotomy a...</td>\n",
       "      <td>Background\\nApproximately 70% of women will ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1002-14651858.CD000009</td>\n",
       "      <td>10.1002-14651858.CD000009.pub4-pls.txt</td>\n",
       "      <td>10.1002-14651858.CD000009.pub4-abstract.txt_se...</td>\n",
       "      <td>Do acupuncture and related therapies help smok...</td>\n",
       "      <td>We included 38 studies. Based on three studies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1002-14651858.CD000012</td>\n",
       "      <td>10.1002-14651858.CD000012.pub4-pls.txt</td>\n",
       "      <td>10.1002-14651858.CD000012.pub4-abstract.txt_se...</td>\n",
       "      <td>Alternative versus conventional institutional ...</td>\n",
       "      <td>Ten trials involving 11,795 women met the incl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04fa4cec-67f2-40f1-bea2-afd77c930217')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-04fa4cec-67f2-40f1-bea2-afd77c930217 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-04fa4cec-67f2-40f1-bea2-afd77c930217');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-9f27738c-2ac1-4567-92c7-6d522e5fa958\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f27738c-2ac1-4567-92c7-6d522e5fa958')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-9f27738c-2ac1-4567-92c7-6d522e5fa958 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                          id                                file_pls  \\\n",
       "0  10.1002-14651858.CD000006  10.1002-14651858.CD000006.pub2-pls.txt   \n",
       "1  10.1002-14651858.CD000009  10.1002-14651858.CD000009.pub4-pls.txt   \n",
       "2  10.1002-14651858.CD000012  10.1002-14651858.CD000012.pub4-pls.txt   \n",
       "\n",
       "                                        file_non_pls  \\\n",
       "0        10.1002-14651858.CD000006.pub2-abstract.txt   \n",
       "1  10.1002-14651858.CD000009.pub4-abstract.txt_se...   \n",
       "2  10.1002-14651858.CD000012.pub4-abstract.txt_se...   \n",
       "\n",
       "                                                 pls  \\\n",
       "0  Absorbable stitches for repair of episiotomy a...   \n",
       "1  Do acupuncture and related therapies help smok...   \n",
       "2  Alternative versus conventional institutional ...   \n",
       "\n",
       "                                             non_pls  \n",
       "0  Background\\nApproximately 70% of women will ex...  \n",
       "1  We included 38 studies. Based on three studies...  \n",
       "2  Ten trials involving 11,795 women met the incl...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NÃºmero mÃ¡ximo de pares\n",
    "pares = 2000\n",
    "\n",
    "# === 1ï¸âƒ£ Listar archivos ===\n",
    "pls_files = sorted(glob.glob(\"data_collection_and_processing/Data Sources/Cochrane/train/pls/*.txt\"))\n",
    "non_pls_files = sorted(glob.glob(\"data_collection_and_processing/Data Sources/Cochrane/train/non_pls/*.txt\"))\n",
    "\n",
    "# === 2ï¸âƒ£ Filtrar archivos que contengan 'accumulated' en AMBOS ---\n",
    "pls_files = [f for f in pls_files if \"accumulated\" not in os.path.basename(f).lower()]\n",
    "non_pls_files = [f for f in non_pls_files if \"accumulated\" not in os.path.basename(f).lower()]\n",
    "\n",
    "print(f\"ğŸ“š Total PLS (sin accumulated): {len(pls_files)}\")\n",
    "print(f\"ğŸ“‚ Total non-PLS (sin accumulated): {len(non_pls_files)}\")\n",
    "\n",
    "# === 3ï¸âƒ£ FunciÃ³n para extraer el ID base ===\n",
    "def extract_id(filename):\n",
    "    base = os.path.basename(filename)\n",
    "    match = re.match(r\"(.+?)\\.pub\\d+\", base)\n",
    "    return match.group(1) if match else base.split(\".txt\")[0]\n",
    "\n",
    "# === 4ï¸âƒ£ Diccionarios {id_base: ruta} ===\n",
    "pls_dict = {extract_id(p): p for p in pls_files}\n",
    "non_pls_dict = {extract_id(n): n for n in non_pls_files}\n",
    "\n",
    "# === 5ï¸âƒ£ Emparejar ===\n",
    "data = []\n",
    "for base_id, non_path in non_pls_dict.items():\n",
    "    if base_id in pls_dict:\n",
    "        pls_path = pls_dict[base_id]\n",
    "        with open(pls_path, \"r\", encoding=\"utf-8\") as f1, open(non_path, \"r\", encoding=\"utf-8\") as f2:\n",
    "            data.append({\n",
    "                \"id\": base_id,\n",
    "                \"file_pls\": os.path.basename(pls_path),\n",
    "                \"file_non_pls\": os.path.basename(non_path),\n",
    "                \"pls\": f1.read().strip(),\n",
    "                \"non_pls\": f2.read().strip()\n",
    "            })\n",
    "    if len(data) >= pares:\n",
    "        break\n",
    "\n",
    "# === 6ï¸âƒ£ DataFrame ===\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# === 7ï¸âƒ£ Guardar ===\n",
    "output_path = \"cochrane_pairs_clean.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\nâœ… Emparejados {len(df)} pares por nombre base (sin 'accumulated' en ninguno)\")\n",
    "print(f\"ğŸ’¾ Guardado en: {output_path}\")\n",
    "df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhjvxOj176DT",
    "outputId": "9aa11a68-9d4b-4bc7-d0ea-43f5033b2126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'response'],\n",
      "        num_rows: 1800\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'response'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "df = df.rename(columns={\"non_pls\": \"source\", \"pls\": \"target\"})\n",
    "\n",
    "INSTR_PROMPT = \"\"\"Using the following abstract of a biomedical study as input, generate a Plain Language Summary\n",
    "(PLS) understandable by any patient, regardless of their health literacy. Ensure that the generated text\n",
    "adheres to the following instructions which should be followed step-by-step:\n",
    "a. Specific Structure: The generated PLS should be presented in a logical order, using the following\n",
    "order:\n",
    "1. Plain Title\n",
    "2. Rationale\n",
    "3. Trial Design\n",
    "4. Results\n",
    "b. Sections should be authored following these parameters:\n",
    "1. Plain Title: Simplified title understandable to a layperson that summarizes the research that was\n",
    "done.\n",
    "2. Rationale: Include: background or study rationale providing a general description of the\n",
    "condition, what it may cause or why it is a burden for the patients; the reason and main hypothesis\n",
    "for the study; and why the study is needed, and why the study medication has the potential to\n",
    "treat the condition.\n",
    "3. Trial Design: Answer â€˜How is this study designed?â€™ Include the description of the design,\n",
    "description of study and patient population (age, health condition, gender), and the expected\n",
    "amount of time a person will be in the study.\n",
    "4. Results: Answer â€˜What were the main results of the studyâ€™, include the benefits for the patients,\n",
    "how the study was relevant for the area of study, and the conclusions from the investigator.\n",
    "c. Consistency and Replicability: The generated PLS should be consistent regardless of the order of\n",
    "sentences or the specific phrasing used in the input protocol text.\n",
    "d. Compliance with Plain Language Guidelines: The generated PLS must follow all these plain\n",
    "language guidelines:\n",
    "â€¢ Have readability grade level of 6 or below.\n",
    "â€¢ Do not have jargon. All technical or medical words or terms should be defined or broken down\n",
    "into simple and logical explanations.\n",
    "â€¢ Active voice, not passive.\n",
    "â€¢ Mostly one or two syllable words.\n",
    "â€¢ Sentences of 15 words or less.\n",
    "â€¢ Short paragraphs of 3-5 sentences.\n",
    "â€¢ Simple numbers (e.g., ratios, no percentages).\n",
    "e. Do not invent Content: The AI model should not invent information. If the AI model includes data\n",
    "other than the one given in the input abstract, the AI model should guarantee such data is verified and\n",
    "real.\n",
    "f. Aim for an approximate PLS length of 500-900 words.\n",
    "\n",
    "Input abstract:\n",
    "\n",
    "{source}\n",
    "\n",
    "Output PLS:\n",
    "\"\"\"\n",
    "\n",
    "def format_example(row):\n",
    "    prompt = INSTR_PROMPT.format(source=row[\"source\"])\n",
    "    return {\"prompt\": prompt, \"response\": row[\"target\"]}\n",
    "\n",
    "# Aplicar la funciÃ³n a cada fila del DataFrame\n",
    "dataset = df.apply(format_example, axis=1).to_list()\n",
    "\n",
    "# Crear Dataset de Hugging Face y dividir en train/test\n",
    "from datasets import Dataset\n",
    "\n",
    "hf_ds = Dataset.from_list(dataset).train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "print(hf_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Um4meHzT77iD",
    "outputId": "116e9043-3e01-4c30-b370-e22aa8ccd61e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ Ejemplo #1424\n",
      "Using the following abstract of a biomedical study as input, generate a Plain Language Summary\n",
      "(PLS) understandable by any patient, regardless of their health literacy. Ensure that the generated text\n",
      "adheres to the following instructions which should be followed step-by-step:\n",
      "a. Specific Structure: The generated PLS should be presented in a logical order, using the following\n",
      "order:\n",
      "1. Plain Title\n",
      "2. Rationale\n",
      "3. Trial Design\n",
      "4. Results\n",
      "b. Sections should be authored following these parameters:\n",
      "1. Plain Title: Simplified title understandable to a layperson that summarizes the research that was\n",
      "done.\n",
      "2. Rationale: Include: background or study rationale providing a general description of the\n",
      "condition, what it may cause or why it is a burden for the patients; the reason and main hypothesis\n",
      "for the study; and why the study is needed, and why the study medication has the potential to\n",
      "treat the condition.\n",
      "3. Trial Design: Answer â€˜How is this study designed?â€™ Include the description of the design,\n",
      "description of study and patient population (age, health condition, gender), and the expected\n",
      "amount of time a person will be in the study.\n",
      "4. Results: Answer â€˜What were the main results of the studyâ€™, include the benefits for the patients,\n",
      "how the study was relevant for the area of study, and the conclusions from the investigator.\n",
      "c. Consistency and Replicability: The generated PLS should be consistent regardless of the order of\n",
      "sentences or the specific phrasing used in the input protocol text.\n",
      "d. Compliance with Plain Language Guidelines: The generated PLS must follow all these plain\n",
      "language guidelines:\n",
      "â€¢ Have readability grade level of 6 or below.\n",
      "â€¢ Do not have jargon. All technical or medical words or terms should be defined or broken down\n",
      "into simple and logical explanations.\n",
      "â€¢ Active voice, not passive.\n",
      "â€¢ Mostly one or two syllable words.\n",
      "â€¢ Sentences of 15 words or less.\n",
      "â€¢ Short paragraphs of 3-5 sentences.\n",
      "â€¢ Simple numbers (e.g., ratios, no percentages).\n",
      "e. Do not invent Content: The AI model should not invent information. If the AI model includes data\n",
      "other than the one given in the input abstract, the AI model should guarantee such data is verified and\n",
      "real.\n",
      "f. Aim for an approximate PLS length of 500-900 words.\n",
      "\n",
      "Input abstract:\n",
      "\n",
      "Background\n",
      "Women may experience differing types of pain and discomfort following birth, including cramping pain (often called afterâ€birth pain) associated with uterine involution, where the uterus contracts to reduce blood loss and return the uterus to its nonâ€pregnant size. This is an update of a review first published in 2011. \n",
      "Objectives\n",
      "To assess the effectiveness and safety of pharmacological and nonâ€pharmacological pain relief/analgesia for the relief of afterâ€birth pains following vaginal birth. \n",
      "Search methods\n",
      "For this update, we searched Cochrane Pregnancy and Childbirthâ€™s Trials Register, ClinicalTrials.gov, the WHO International Clinical Trials Registry Platform (ICTRP) (31 October 2019), and reference lists of retrieved studies. \n",
      "Selection criteria\n",
      "Randomised controlled trials comparing two different types of analgesia or analgesia versus placebo or analgesia versus no treatment, for the relief of afterâ€birth pains following vaginal birth. Types of analgesia included pharmacological and nonâ€pharmacological. Quasiâ€randomised trials were not eligible for inclusion. \n",
      "Data collection and analysis\n",
      "Two review authors independently assessed trials for inclusion, conducted 'Risk of bias' assessment, extracted data and assessed the certainty of the evidence using the GRADE approach. \n",
      "Main results\n",
      "In this update, we include 28 studies (involving 2749 women). The evidence identified in this review comes from middleâ€ to highâ€income countries. Generally the trials were at low risk of selection bias, performance bias and attrition bias, but some trials were at high risk of bias due to selective reporting and lack of blinding. Our GRADE certainty of evidence assessments ranged from moderate to very low certainty, with downgrading decisions based on study limitations, imprecision, and (for one comparison) indirectness. \n",
      "Most studies reported our primary outcome of adequate pain relief as reported by the women. No studies reported data relating to neonatal adverse events, duration of hospital stay, or breastfeeding rates. Almost half of the included studies (11/28) excluded breastfeeding women from participating, making the evidence less generalisable to a broader group of women. \n",
      "Nonâ€steroidal antiâ€inflammatory drugs (NSAIDs) compared to placebo \n",
      "NSAIDs are probably better than placebo for adequate pain relief as reported by the women (risk ratio (RR) 1.66, 95% confidence interval (CI) 1.45 to 1.91; 11 studies, 946 women; moderateâ€certainty evidence). NSAIDs may reduce the need for additional pain relief compared to placebo (RR 0.15, 95% CI 0.07 to 0.33; 4 studies, 375 women; lowâ€certainty evidence). There may be a similar risk of maternal adverse events (RR 1.05, 95% CI 0.78 to 1.41; 9 studies, 598 women; lowâ€certainty evidence). \n",
      "NSAIDs compared to opioids \n",
      "NSAIDs are probably better than opioids for adequate pain relief as reported by the women (RR 1.33, 95% CI 1.13 to 1.57; 5 studies, 560 women; moderateâ€certainty evidence) and may reduce the risk of maternal adverse events (RR 0.62, 95% CI 0.43 to 0.89; 3 studies, 255 women; lowâ€certainty evidence). NSAIDs may be better than opioids for the need for additional pain relief, but the wide CIs include the possibility that the two classes of drugs are similarly effective or that opioids are better (RR 0.37, 95% CI 0.12 to 1.12; 2 studies, 232 women; lowâ€certainty evidence). \n",
      "Opioids compared to placebo \n",
      "Opioids may be better than placebo for adequate pain relief as reported by the women (RR 1.26, 95% CI 0.99 to 1.61; 5 studies, 299 women; lowâ€certainty evidence). Opioids may reduce the need for additional pain relief compared to placebo (RR 0.48, 95% CI 0.28 to 0.82; 3 studies, 273 women; lowâ€certainty evidence). Opioids may increase the risk of maternal adverse events compared with placebo, although the certainty of evidence is low (RR 1.59, 95% CI 0.99 to 2.55; 3 studies, 188 women; lowâ€certainty evidence). \n",
      "Paracetamol compared to placebo \n",
      "Very lowâ€certainty evidence means we are uncertain if paracetamol is better than placebo for adequate pain relief as reported by the women, the need for additional pain relief, or risk of maternal adverse events (2 studies, 123 women). \n",
      "Paracetamol compared to NSAIDs \n",
      "Very lowâ€certainty evidence means we are uncertain if there are any differences between paracetamol and NSAIDs for adequate pain relief as reported by the women, or the risk of maternal adverse events. No data were reported about the need for additional pain relief comparing paracetamol and NSAIDs (2 studies, 112 women). \n",
      "NSAIDs compared to herbal analgesia \n",
      "We are uncertain if there are any differences between NSAIDs and herbal analgesia for adequate pain relief as reported by the women, the need for additional pain relief, or risk of maternal adverse events, because the certainty of evidence is very low (4 studies, 394 women). \n",
      "Transcutaneous nerve stimulation (TENS) compared to no TENS \n",
      "Very lowâ€certainty evidence means we are uncertain if TENS is better than no TENS for adequate pain relief as reported by the women. No other data were reported comparing TENS with no TENS (1 study, 32 women). \n",
      "Authors' conclusions\n",
      "NSAIDs may be better than placebo and are probably better than opioids at relieving pain from uterine cramping/involution following vaginal birth. NSAIDs and paracetamol may be as effective as each other, whereas opioids may be more effective than placebo. Due to lowâ€certainty evidence, we are uncertain about the effectiveness of other forms of pain relief. Future trials should recruit adequate numbers of women and ensure greater generalisability by including breastfeeding women. In addition, further research is required, including a survey of postpartum women to describe appropriately their experience of uterine cramping and involution. We identified nine ongoing studies, which may help to increase the level of certainty of the evidence around pain relief due to uterine cramping in future updates of this review.\n",
      "\n",
      "Output PLS:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "idx = random.randint(0, len(hf_ds[\"train\"]) - 1)\n",
    "print(f\"ğŸ”¹ Ejemplo #{idx}\")\n",
    "print(hf_ds[\"train\"][idx][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8gKF6Dtm79l6"
   },
   "outputs": [],
   "source": [
    "MODELO=\"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "num_train_epochs=4\n",
    "COSINE_WEIGHT=0      # Desactivado\n",
    "KL_WEIGHT=0.1        # Activado (foco principal)\n",
    "READABILITY_WEIGHT=0\n",
    "COMPLEXITY_WEIGHT=0\n",
    "base_model_name=\"Qwen/Qwen2.5-1.5B-Instruct\" # teacher para KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5537304b6d8744cc802c2384807f56b9",
      "c119c23995a04272b83597228a74bd13",
      "9c550998c3ce47babbda9d0f2bb6b945",
      "08453c901efe461b878a122f0b917a7b",
      "d7507b1ad96e43468d250626fcbc1c3c",
      "4161910787b043428f2ce953dd866900",
      "af9553b10b5745b992be72cbc703575b",
      "37d99fa14016472591c52afde0d1763f",
      "abff7e6737cf4d6b8d499cd063324811",
      "5f3b1125f89a4770927912fa23125d31",
      "f4911d3c01bd4025bd4ea35edd81a44f",
      "50438ecfdc4f4b71a7ea389d2839f43e",
      "99417e3f6c80483c8eadec04e190fcd0",
      "0c2e8b4468c54b38a0f8ce9c666ac009",
      "6000ed00cda94390855749b99295e5d6",
      "850b6ba459344cb0980a1b974dec3828",
      "a360471cb2ec4b6a90f450803c951872",
      "3c568d3ca9fc4146808627d289759d2b",
      "1dae673b3ea04a11bce5efea3b3cce3f",
      "2f9a3ed0ec1d441fa87614c3e69cd1ab",
      "b615befe1b9c43939267e6dc7842bf59",
      "0a9a18caf5664c6f8cca412c5dbe6338",
      "4932a2f8676141a98381938e12b67aad",
      "9da4d26eb9ea4c138ebe3396bb64a0c6",
      "c13db08f76f8411490911da5fc53d588",
      "7d8b8c1787034d8e8b77e9c13ea6570e",
      "a0e6f63ea71b4ddfbbdb89e852e7184a",
      "b295d53087d942b48d65419ab989fe42",
      "056adfcfb0574e4baa63f98dbd2f1120",
      "10c2184e66b944eba8a92fc85c86156f",
      "a180900ff1a047a1984b63413b96d52c",
      "6ab86f8b096e49f295c010ec103b37f9",
      "d0ef656d704240fc80e53fac9fef6c41",
      "3f7bf3a1ab8b4d4e96d0677382c98418",
      "ab746e1122924a8baeb042cab61c10c2",
      "ae3deacd7aa847c3bf93e3528c4ad1af",
      "57b014f559184e0c900981e211dec9cb",
      "aee0ca91cf074ae0ba7a792a8df68c96",
      "3c5421a232ee41908680fdbae51fff21",
      "50e25e44abf04f1ca178adcd4503c769",
      "a39ec16f891740099d32e247922a85b9",
      "b28b0e600ef44bbbbc9d49241c5f9eef",
      "741eef0f3c3f469db58c5363893eb737",
      "f7cdca9d226b4bcc869d827a651593db",
      "df7a6db0696748869888fe72d8b77a0c",
      "8cb746ccb60844358a0820283c829553",
      "db48c6119c3646e79809acdf393de949",
      "ff86e1210ed14cf1a5e0d983db8c92d5",
      "b4a45082faa141b9a5978035295f4480",
      "f5da069cb60143bc99707792098e87fe",
      "adcbeb5dd91a466790402f3159a8bb61",
      "9026b1dc4e374cb3a4fbd8d141582013",
      "259d0c5876f44edf8564ef5619a42c29",
      "bb8ad40844a1421b8a67e22b6830ab06",
      "5cac331a544947efb6e69cf43755b507",
      "2f6728b05dd94d249c79743d7eb5f0b6",
      "e853212b84f54c988894208eba82db2e",
      "9fda0c02cfbb47e7aa0d01105f75c96a",
      "9f3c29bb6474429795308334add66244",
      "d226fb147f554c66827793af4a8c5024",
      "98ebe9b69e944d0bbbae38ce9f312339",
      "edf0a59d523741d7956b2b47eb94016f",
      "c6481e51b18a44f4a99296224973003d",
      "c48aeb916746424cbf2ea98c67f526bb",
      "a331cbbcc6be4c21852dfcf573aa6a48",
      "e176652fc1b5491e9ae36c747927dd3a",
      "034a43c5d434418f9615a69faa4a7f32",
      "bd39def12140423b96e8b9affc0473aa",
      "7f8e3653bd594e9592357673ccd9f0aa",
      "be154edc013f4e5d873fd0f4753d6077",
      "d675650999a94c4db2aadc2fe5b50c11",
      "b955ee8ccf8747bd87a07cfbc261b247",
      "a9fa8771c4d64863a02f2f35fbbcd8ca",
      "b3b0a7b7384643ed81b38fa6f63c7341",
      "e81c82a29f0d46b080120e633acbf027",
      "83518bb99aa84f63b9f0ffdbe3c818ae",
      "ae69ad33d94140808c576f5091ebb3e3"
     ]
    },
    "id": "NarEPjic8HTu",
    "outputId": "19573e50-715f-487a-8bee-aaa33a052e12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
      "Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"layer_types\": [\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "Overriding dtype=None with `dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own dtype to specify the dtype of the remaining non-linear layers or pass dtype=torch.float16 to remove this warning.\n",
      "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/model.safetensors\n",
      "Instantiating Qwen2ForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸš‘ MODO RESCATE: ANTI-NAN + DIAGNÃ“STICO DE DATOS\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "target_dtype {target_dtype} is replaced by `CustomDtype.INT4` for 4-bit BnB quantization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5537304b6d8744cc802c2384807f56b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"temperature\": 0.7,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n",
      "Could not locate the custom_generate/generate.py inside Qwen/Qwen2.5-1.5B-Instruct.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50438ecfdc4f4b71a7ea389d2839f43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4932a2f8676141a98381938e12b67aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7bf3a1ab8b4d4e96d0677382c98418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7a6db0696748869888fe72d8b77a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/vocab.json\n",
      "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/merges.txt\n",
      "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
      "Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"layer_types\": [\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "Overriding dtype=None with `dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own dtype to specify the dtype of the remaining non-linear layers or pass dtype=torch.float16 to remove this warning.\n",
      "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/model.safetensors\n",
      "Instantiating Qwen2ForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n",
      "target_dtype {target_dtype} is replaced by `CustomDtype.INT4` for 4-bit BnB quantization\n",
      "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"temperature\": 0.7,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n",
      "Could not locate the custom_generate/generate.py inside Qwen/Qwen2.5-1.5B-Instruct.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Tokenizando...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6728b05dd94d249c79743d7eb5f0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034a43c5d434418f9615a69faa4a7f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using auto half precision backend\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151645}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "ğŸ§ INSPECCIÃ“N DE DATOS\n",
      "Tokens Totales: 1024\n",
      "Tokens VÃ¡lidos (Labels): 105\n",
      "âœ… DATOS OK. El modelo tiene quÃ© aprender.\n",
      "========================================\n",
      "\n",
      "\n",
      "ğŸš€ INICIANDO ENTRENAMIENTO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipped Embedding(151936, 1536): 222.5625M params\n",
      "skipped: 222.5625M params\n",
      "***** Running training *****\n",
      "  Num examples = 162\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 32\n",
      "  Total optimization steps = 24\n",
      "  Number of trainable parameters = 9,232,384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 | Total: 2.6373 | CE: 2.6373 | KL: 0.0000\n",
      "Step 0 | Total: 2.4873 | CE: 2.4873 | KL: 0.0000\n",
      "Step 0 | Total: 1.7406 | CE: 1.7406 | KL: 0.0000\n",
      "Step 0 | Total: 3.8081 | CE: 3.8081 | KL: 0.0000\n",
      "Step 0 | Total: 3.8851 | CE: 3.8851 | KL: 0.0000\n",
      "Step 0 | Total: 3.0783 | CE: 3.0783 | KL: 0.0000\n",
      "Step 0 | Total: 1.8982 | CE: 1.8982 | KL: 0.0000\n",
      "Step 0 | Total: 2.2082 | CE: 2.2082 | KL: 0.0000\n",
      "Step 0 | Total: 3.1277 | CE: 3.1277 | KL: 0.0000\n",
      "Step 0 | Total: 1.8287 | CE: 1.8287 | KL: 0.0000\n",
      "Step 0 | Total: 1.5400 | CE: 1.5400 | KL: 0.0000\n",
      "Step 0 | Total: 2.4898 | CE: 2.4898 | KL: 0.0000\n",
      "Step 0 | Total: 1.7966 | CE: 1.7966 | KL: 0.0000\n",
      "Step 0 | Total: 2.6550 | CE: 2.6550 | KL: 0.0000\n",
      "Step 0 | Total: 6.4866 | CE: 6.4866 | KL: 0.0000\n",
      "Step 0 | Total: 6.9123 | CE: 6.9123 | KL: 0.0000\n",
      "Step 0 | Total: 3.6157 | CE: 3.6157 | KL: 0.0000\n",
      "Step 0 | Total: 2.4431 | CE: 2.4431 | KL: 0.0000\n",
      "Step 0 | Total: 11.5484 | CE: 11.5484 | KL: 0.0000\n",
      "Step 0 | Total: 2.0053 | CE: 2.0053 | KL: 0.0000\n",
      "Step 0 | Total: 2.1292 | CE: 2.1292 | KL: 0.0000\n",
      "Step 0 | Total: 2.7179 | CE: 2.7179 | KL: 0.0000\n",
      "Step 0 | Total: 4.7219 | CE: 4.7219 | KL: 0.0000\n",
      "Step 0 | Total: 6.4845 | CE: 6.4845 | KL: 0.0000\n",
      "Step 0 | Total: 2.8856 | CE: 2.8856 | KL: 0.0000\n",
      "Step 0 | Total: 3.0823 | CE: 3.0823 | KL: 0.0000\n",
      "Step 0 | Total: 2.2946 | CE: 2.2946 | KL: 0.0000\n",
      "Step 0 | Total: 2.6394 | CE: 2.6394 | KL: 0.0000\n",
      "Step 0 | Total: 12.6820 | CE: 12.6820 | KL: 0.0000\n",
      "Step 0 | Total: 1.9765 | CE: 1.9765 | KL: 0.0000\n",
      "Step 0 | Total: 4.1550 | CE: 4.1550 | KL: 0.0000\n",
      "Step 0 | Total: 4.5676 | CE: 4.5676 | KL: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 05:29, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>118.528700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>107.539600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>82.570100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>108.730800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>105.157600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.245100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>109.176400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>104.119400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>91.820600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>113.456000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>96.243300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>5.276600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>119.752600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>91.785900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>103.523500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>110.794400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>80.374100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>5.804900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>79.488300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>128.304900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>107.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>100.510400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>86.105500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>6.048300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Total: 2.4853 | CE: 2.4853 | KL: 0.0000\n",
      "Step 1 | Total: 4.7334 | CE: 4.7334 | KL: 0.0000\n",
      "Step 1 | Total: 2.4430 | CE: 2.4430 | KL: 0.0000\n",
      "Step 1 | Total: 2.4708 | CE: 2.4708 | KL: 0.0000\n",
      "Step 1 | Total: 2.3594 | CE: 2.3594 | KL: 0.0000\n",
      "Step 1 | Total: 17.5465 | CE: 17.5465 | KL: 0.0000\n",
      "Step 1 | Total: 1.1056 | CE: 1.1056 | KL: 0.0000\n",
      "Step 1 | Total: 2.6136 | CE: 2.6136 | KL: 0.0000\n",
      "Step 1 | Total: 3.1453 | CE: 3.1453 | KL: 0.0000\n",
      "Step 1 | Total: 1.8334 | CE: 1.8334 | KL: 0.0000\n",
      "Step 1 | Total: 2.8113 | CE: 2.8113 | KL: 0.0000\n",
      "Step 1 | Total: 3.8134 | CE: 3.8134 | KL: 0.0000\n",
      "Step 1 | Total: 2.5418 | CE: 2.5418 | KL: 0.0000\n",
      "Step 1 | Total: 1.7606 | CE: 1.7606 | KL: 0.0000\n",
      "Step 1 | Total: 2.4955 | CE: 2.4955 | KL: 0.0000\n",
      "Step 1 | Total: 3.0359 | CE: 3.0359 | KL: 0.0000\n",
      "Step 1 | Total: 2.4362 | CE: 2.4362 | KL: 0.0000\n",
      "Step 1 | Total: 1.8320 | CE: 1.8320 | KL: 0.0000\n",
      "Step 1 | Total: 3.7094 | CE: 3.7094 | KL: 0.0000\n",
      "Step 1 | Total: 5.4766 | CE: 5.4766 | KL: 0.0000\n",
      "Step 1 | Total: 2.9041 | CE: 2.9041 | KL: 0.0000\n",
      "Step 1 | Total: 2.2396 | CE: 2.2396 | KL: 0.0000\n",
      "Step 1 | Total: 5.1138 | CE: 5.1138 | KL: 0.0000\n",
      "Step 1 | Total: 2.6228 | CE: 2.6228 | KL: 0.0000\n",
      "Step 1 | Total: 2.8194 | CE: 2.8194 | KL: 0.0000\n",
      "Step 1 | Total: 3.0781 | CE: 3.0781 | KL: 0.0000\n",
      "Step 1 | Total: 2.0005 | CE: 2.0005 | KL: 0.0000\n",
      "Step 1 | Total: 3.8999 | CE: 3.8999 | KL: 0.0000\n",
      "Step 1 | Total: 2.7835 | CE: 2.7835 | KL: 0.0000\n",
      "Step 1 | Total: 4.9849 | CE: 4.9849 | KL: 0.0000\n",
      "Step 1 | Total: 2.0426 | CE: 2.0426 | KL: 0.0000\n",
      "Step 1 | Total: 2.4015 | CE: 2.4015 | KL: 0.0000\n",
      "Step 2 | Total: 2.1263 | CE: 2.1263 | KL: 0.0000\n",
      "Step 2 | Total: 1.5345 | CE: 1.5345 | KL: 0.0000\n",
      "Step 2 | Total: 4.0423 | CE: 4.0423 | KL: 0.0000\n",
      "Step 2 | Total: 1.7172 | CE: 1.7172 | KL: 0.0000\n",
      "Step 2 | Total: 1.6085 | CE: 1.6085 | KL: 0.0000\n",
      "Step 2 | Total: 2.3487 | CE: 2.3487 | KL: 0.0000\n",
      "Step 2 | Total: 2.8119 | CE: 2.8119 | KL: 0.0000\n",
      "Step 2 | Total: 2.4582 | CE: 2.4582 | KL: 0.0000\n",
      "Step 2 | Total: 2.3287 | CE: 2.3287 | KL: 0.0000\n",
      "Step 2 | Total: 2.9054 | CE: 2.9054 | KL: 0.0000\n",
      "Step 2 | Total: 2.3834 | CE: 2.3834 | KL: 0.0000\n",
      "Step 2 | Total: 2.1355 | CE: 2.1355 | KL: 0.0000\n",
      "Step 2 | Total: 2.1738 | CE: 2.1738 | KL: 0.0000\n",
      "Step 2 | Total: 3.2266 | CE: 3.2266 | KL: 0.0000\n",
      "Step 2 | Total: 2.9645 | CE: 2.9645 | KL: 0.0000\n",
      "Step 2 | Total: 3.3745 | CE: 3.3745 | KL: 0.0000\n",
      "Step 2 | Total: 1.5159 | CE: 1.5159 | KL: 0.0000\n",
      "Step 2 | Total: 1.9739 | CE: 1.9739 | KL: 0.0000\n",
      "Step 2 | Total: 4.1543 | CE: 4.1543 | KL: 0.0000\n",
      "Step 2 | Total: 1.9679 | CE: 1.9679 | KL: 0.0000\n",
      "Step 2 | Total: 2.5151 | CE: 2.5151 | KL: 0.0000\n",
      "Step 2 | Total: 3.6542 | CE: 3.6542 | KL: 0.0000\n",
      "Step 2 | Total: 3.1378 | CE: 3.1378 | KL: 0.0000\n",
      "Step 2 | Total: 3.8458 | CE: 3.8458 | KL: 0.0000\n",
      "Step 2 | Total: 2.1118 | CE: 2.1118 | KL: 0.0000\n",
      "Step 2 | Total: 2.4902 | CE: 2.4902 | KL: 0.0000\n",
      "Step 2 | Total: 1.9603 | CE: 1.9603 | KL: 0.0000\n",
      "Step 2 | Total: 2.7174 | CE: 2.7174 | KL: 0.0000\n",
      "Step 2 | Total: 3.8023 | CE: 3.8023 | KL: 0.0000\n",
      "Step 2 | Total: 2.6496 | CE: 2.6496 | KL: 0.0000\n",
      "Step 2 | Total: 2.1424 | CE: 2.1424 | KL: 0.0000\n",
      "Step 2 | Total: 1.7911 | CE: 1.7911 | KL: 0.0000\n",
      "Step 3 | Total: 4.4858 | CE: 4.4858 | KL: 0.0000\n",
      "Step 3 | Total: 1.8153 | CE: 1.8153 | KL: 0.0000\n",
      "Step 3 | Total: 2.5433 | CE: 2.5433 | KL: 0.0000\n",
      "Step 3 | Total: 2.7112 | CE: 2.7112 | KL: 0.0000\n",
      "Step 3 | Total: 2.3094 | CE: 2.3094 | KL: 0.0000\n",
      "Step 3 | Total: 2.3754 | CE: 2.3754 | KL: 0.0000\n",
      "Step 3 | Total: 2.5279 | CE: 2.5279 | KL: 0.0000\n",
      "Step 3 | Total: 2.4791 | CE: 2.4791 | KL: 0.0000\n",
      "Step 3 | Total: 3.0045 | CE: 3.0045 | KL: 0.0000\n",
      "Step 3 | Total: 2.1292 | CE: 2.1292 | KL: 0.0000\n",
      "Step 3 | Total: 4.3612 | CE: 4.3612 | KL: 0.0000\n",
      "Step 3 | Total: 1.6783 | CE: 1.6783 | KL: 0.0000\n",
      "Step 3 | Total: 3.8533 | CE: 3.8533 | KL: 0.0000\n",
      "Step 3 | Total: 2.9263 | CE: 2.9263 | KL: 0.0000\n",
      "Step 3 | Total: 13.1743 | CE: 13.1743 | KL: 0.0000\n",
      "Step 3 | Total: 5.3426 | CE: 5.3426 | KL: 0.0000\n",
      "Step 3 | Total: 4.3874 | CE: 4.3874 | KL: 0.0000\n",
      "Step 3 | Total: 3.7061 | CE: 3.7061 | KL: 0.0000\n",
      "Step 3 | Total: 2.8668 | CE: 2.8668 | KL: 0.0000\n",
      "Step 3 | Total: 9.4908 | CE: 9.4908 | KL: 0.0000\n",
      "Step 3 | Total: 2.0564 | CE: 2.0564 | KL: 0.0000\n",
      "Step 3 | Total: 3.3696 | CE: 3.3696 | KL: 0.0000\n",
      "Step 3 | Total: 2.6112 | CE: 2.6112 | KL: 0.0000\n",
      "Step 3 | Total: 2.3037 | CE: 2.3037 | KL: 0.0000\n",
      "Step 3 | Total: 3.1735 | CE: 3.1735 | KL: 0.0000\n",
      "Step 3 | Total: 2.2858 | CE: 2.2858 | KL: 0.0000\n",
      "Step 3 | Total: 2.6435 | CE: 2.6435 | KL: 0.0000\n",
      "Step 3 | Total: 2.4978 | CE: 2.4978 | KL: 0.0000\n",
      "Step 3 | Total: 2.9776 | CE: 2.9776 | KL: 0.0000\n",
      "Step 3 | Total: 1.8822 | CE: 1.8822 | KL: 0.0000\n",
      "Step 3 | Total: 2.4025 | CE: 2.4025 | KL: 0.0000\n",
      "Step 3 | Total: 2.3589 | CE: 2.3589 | KL: 0.0000\n",
      "Step 4 | Total: 4.5018 | CE: 4.5018 | KL: 0.0000\n",
      "Step 4 | Total: 2.2064 | CE: 2.2064 | KL: 0.0000\n",
      "Step 4 | Total: 1.9205 | CE: 1.9205 | KL: 0.0000\n",
      "Step 4 | Total: 2.3720 | CE: 2.3720 | KL: 0.0000\n",
      "Step 4 | Total: 2.5167 | CE: 2.5167 | KL: 0.0000\n",
      "Step 4 | Total: 1.5527 | CE: 1.5527 | KL: 0.0000\n",
      "Step 4 | Total: 2.9345 | CE: 2.9345 | KL: 0.0000\n",
      "Step 4 | Total: 2.0840 | CE: 2.0840 | KL: 0.0000\n",
      "Step 4 | Total: 3.1456 | CE: 3.1456 | KL: 0.0000\n",
      "Step 4 | Total: 2.6264 | CE: 2.6264 | KL: 0.0000\n",
      "Step 4 | Total: 2.2177 | CE: 2.2177 | KL: 0.0000\n",
      "Step 4 | Total: 1.9672 | CE: 1.9672 | KL: 0.0000\n",
      "Step 4 | Total: 3.1828 | CE: 3.1828 | KL: 0.0000\n",
      "Step 4 | Total: 4.1550 | CE: 4.1550 | KL: 0.0000\n",
      "Step 4 | Total: 2.4675 | CE: 2.4675 | KL: 0.0000\n",
      "Step 4 | Total: 3.8513 | CE: 3.8513 | KL: 0.0000\n",
      "Step 4 | Total: 1.8593 | CE: 1.8593 | KL: 0.0000\n",
      "Step 4 | Total: 3.1158 | CE: 3.1158 | KL: 0.0000\n",
      "Step 4 | Total: 2.1388 | CE: 2.1388 | KL: 0.0000\n",
      "Step 4 | Total: 2.6158 | CE: 2.6158 | KL: 0.0000\n",
      "Step 4 | Total: 3.7193 | CE: 3.7193 | KL: 0.0000\n",
      "Step 4 | Total: 1.9971 | CE: 1.9971 | KL: 0.0000\n",
      "Step 4 | Total: 3.6348 | CE: 3.6348 | KL: 0.0000\n",
      "Step 4 | Total: 2.0636 | CE: 2.0636 | KL: 0.0000\n",
      "Step 4 | Total: 3.2046 | CE: 3.2046 | KL: 0.0000\n",
      "Step 4 | Total: 3.9150 | CE: 3.9150 | KL: 0.0000\n",
      "Step 4 | Total: 2.9870 | CE: 2.9870 | KL: 0.0000\n",
      "Step 4 | Total: 18.3015 | CE: 18.3015 | KL: 0.0000\n",
      "Step 4 | Total: 2.6832 | CE: 2.6832 | KL: 0.0000\n",
      "Step 4 | Total: 3.9098 | CE: 3.9098 | KL: 0.0000\n",
      "Step 4 | Total: 2.5482 | CE: 2.5482 | KL: 0.0000\n",
      "Step 4 | Total: 2.7619 | CE: 2.7619 | KL: 0.0000\n",
      "Step 5 | Total: 2.5964 | CE: 2.5964 | KL: 0.0000\n",
      "Step 5 | Total: 3.6487 | CE: 3.6487 | KL: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to gemma_debug/checkpoint-6\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
      "Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"layer_types\": [\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "chat template saved in gemma_debug/checkpoint-6/chat_template.jinja\n",
      "tokenizer config file saved in gemma_debug/checkpoint-6/tokenizer_config.json\n",
      "Special tokens file saved in gemma_debug/checkpoint-6/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6 | Total: 2.4344 | CE: 2.4344 | KL: 0.0000\n",
      "Step 6 | Total: 1.5259 | CE: 1.5259 | KL: 0.0000\n",
      "Step 6 | Total: 3.8990 | CE: 3.8990 | KL: 0.0000\n",
      "Step 6 | Total: 2.6515 | CE: 2.6515 | KL: 0.0000\n",
      "Step 6 | Total: 1.8042 | CE: 1.8042 | KL: 0.0000\n",
      "Step 6 | Total: 2.2291 | CE: 2.2291 | KL: 0.0000\n",
      "Step 6 | Total: 4.1221 | CE: 4.1221 | KL: 0.0000\n",
      "Step 6 | Total: 2.7885 | CE: 2.7885 | KL: 0.0000\n",
      "Step 6 | Total: 1.4981 | CE: 1.4981 | KL: 0.0000\n",
      "Step 6 | Total: 1.9613 | CE: 1.9613 | KL: 0.0000\n",
      "Step 6 | Total: 2.0361 | CE: 2.0361 | KL: 0.0000\n",
      "Step 6 | Total: 1.9154 | CE: 1.9154 | KL: 0.0000\n",
      "Step 6 | Total: 1.5448 | CE: 1.5448 | KL: 0.0000\n",
      "Step 6 | Total: 2.6954 | CE: 2.6954 | KL: 0.0000\n",
      "Step 6 | Total: 2.4368 | CE: 2.4368 | KL: 0.0000\n",
      "Step 6 | Total: 2.6104 | CE: 2.6104 | KL: 0.0000\n",
      "Step 6 | Total: 2.1314 | CE: 2.1314 | KL: 0.0000\n",
      "Step 6 | Total: 2.1824 | CE: 2.1824 | KL: 0.0000\n",
      "Step 6 | Total: 1.8546 | CE: 1.8546 | KL: 0.0000\n",
      "Step 6 | Total: 4.4623 | CE: 4.4623 | KL: 0.0000\n",
      "Step 6 | Total: 2.2932 | CE: 2.2932 | KL: 0.0000\n",
      "Step 6 | Total: 3.6876 | CE: 3.6876 | KL: 0.0000\n",
      "Step 6 | Total: 18.0078 | CE: 18.0078 | KL: 0.0000\n",
      "Step 6 | Total: 12.4850 | CE: 12.4850 | KL: 0.0000\n",
      "Step 6 | Total: 4.6952 | CE: 4.6952 | KL: 0.0000\n",
      "Step 6 | Total: 2.8928 | CE: 2.8928 | KL: 0.0000\n",
      "Step 6 | Total: 3.6326 | CE: 3.6326 | KL: 0.0000\n",
      "Step 6 | Total: 2.6297 | CE: 2.6297 | KL: 0.0000\n",
      "Step 6 | Total: 2.4806 | CE: 2.4806 | KL: 0.0000\n",
      "Step 6 | Total: 2.5051 | CE: 2.5051 | KL: 0.0000\n",
      "Step 6 | Total: 2.6101 | CE: 2.6101 | KL: 0.0000\n",
      "Step 6 | Total: 2.4728 | CE: 2.4728 | KL: 0.0000\n",
      "Step 7 | Total: 2.8647 | CE: 2.8647 | KL: 0.0000\n",
      "Step 7 | Total: 1.9457 | CE: 1.9457 | KL: 0.0000\n",
      "Step 7 | Total: 1.7889 | CE: 1.7889 | KL: 0.0000\n",
      "Step 7 | Total: 2.1271 | CE: 2.1271 | KL: 0.0000\n",
      "Step 7 | Total: 1.6930 | CE: 1.6930 | KL: 0.0000\n",
      "Step 7 | Total: 2.5970 | CE: 2.5970 | KL: 0.0000\n",
      "Step 7 | Total: 5.2880 | CE: 5.2880 | KL: 0.0000\n",
      "Step 7 | Total: 3.6221 | CE: 3.6221 | KL: 0.0000\n",
      "Step 7 | Total: 4.8366 | CE: 4.8366 | KL: 0.0000\n",
      "Step 7 | Total: 3.1346 | CE: 3.1346 | KL: 0.0000\n",
      "Step 7 | Total: 3.1130 | CE: 3.1130 | KL: 0.0000\n",
      "Step 7 | Total: 4.0916 | CE: 4.0916 | KL: 0.0000\n",
      "Step 7 | Total: 2.1301 | CE: 2.1301 | KL: 0.0000\n",
      "Step 7 | Total: 3.5574 | CE: 3.5574 | KL: 0.0000\n",
      "Step 7 | Total: 2.0382 | CE: 2.0382 | KL: 0.0000\n",
      "Step 7 | Total: 4.4673 | CE: 4.4673 | KL: 0.0000\n",
      "Step 7 | Total: 2.0981 | CE: 2.0981 | KL: 0.0000\n",
      "Step 7 | Total: 6.3514 | CE: 6.3514 | KL: 0.0000\n",
      "Step 7 | Total: 2.1201 | CE: 2.1201 | KL: 0.0000\n",
      "Step 7 | Total: 1.5963 | CE: 1.5963 | KL: 0.0000\n",
      "Step 7 | Total: 4.3363 | CE: 4.3363 | KL: 0.0000\n",
      "Step 7 | Total: 2.6816 | CE: 2.6816 | KL: 0.0000\n",
      "Step 7 | Total: 2.5188 | CE: 2.5188 | KL: 0.0000\n",
      "Step 7 | Total: 2.5172 | CE: 2.5172 | KL: 0.0000\n",
      "Step 7 | Total: 12.8412 | CE: 12.8412 | KL: 0.0000\n",
      "Step 7 | Total: 3.8100 | CE: 3.8100 | KL: 0.0000\n",
      "Step 7 | Total: 2.9879 | CE: 2.9879 | KL: 0.0000\n",
      "Step 7 | Total: 2.1931 | CE: 2.1931 | KL: 0.0000\n",
      "Step 7 | Total: 2.0839 | CE: 2.0839 | KL: 0.0000\n",
      "Step 7 | Total: 1.8847 | CE: 1.8847 | KL: 0.0000\n",
      "Step 7 | Total: 3.0604 | CE: 3.0604 | KL: 0.0000\n",
      "Step 7 | Total: 1.7430 | CE: 1.7430 | KL: 0.0000\n",
      "Step 8 | Total: 2.3106 | CE: 2.3106 | KL: 0.0000\n",
      "Step 8 | Total: 1.9378 | CE: 1.9378 | KL: 0.0000\n",
      "Step 8 | Total: 1.9766 | CE: 1.9766 | KL: 0.0000\n",
      "Step 8 | Total: 2.4271 | CE: 2.4271 | KL: 0.0000\n",
      "Step 8 | Total: 1.9574 | CE: 1.9574 | KL: 0.0000\n",
      "Step 8 | Total: 3.7929 | CE: 3.7929 | KL: 0.0000\n",
      "Step 8 | Total: 1.8730 | CE: 1.8730 | KL: 0.0000\n",
      "Step 8 | Total: 3.6892 | CE: 3.6892 | KL: 0.0000\n",
      "Step 8 | Total: 2.6473 | CE: 2.6473 | KL: 0.0000\n",
      "Step 8 | Total: 6.7092 | CE: 6.7092 | KL: 0.0000\n",
      "Step 8 | Total: 1.9806 | CE: 1.9806 | KL: 0.0000\n",
      "Step 8 | Total: 3.1131 | CE: 3.1131 | KL: 0.0000\n",
      "Step 8 | Total: 2.1729 | CE: 2.1729 | KL: 0.0000\n",
      "Step 8 | Total: 3.9959 | CE: 3.9959 | KL: 0.0000\n",
      "Step 8 | Total: 1.5131 | CE: 1.5131 | KL: 0.0000\n",
      "Step 8 | Total: 2.3415 | CE: 2.3415 | KL: 0.0000\n",
      "Step 8 | Total: 2.6261 | CE: 2.6261 | KL: 0.0000\n",
      "Step 8 | Total: 2.7455 | CE: 2.7455 | KL: 0.0000\n",
      "Step 8 | Total: 2.4480 | CE: 2.4480 | KL: 0.0000\n",
      "Step 8 | Total: 2.7200 | CE: 2.7200 | KL: 0.0000\n",
      "Step 8 | Total: 2.5943 | CE: 2.5943 | KL: 0.0000\n",
      "Step 8 | Total: 2.4255 | CE: 2.4255 | KL: 0.0000\n",
      "Step 8 | Total: 3.8080 | CE: 3.8080 | KL: 0.0000\n",
      "Step 8 | Total: 3.6765 | CE: 3.6765 | KL: 0.0000\n",
      "Step 8 | Total: 2.5235 | CE: 2.5235 | KL: 0.0000\n",
      "Step 8 | Total: 3.0332 | CE: 3.0332 | KL: 0.0000\n",
      "Step 8 | Total: 4.9277 | CE: 4.9277 | KL: 0.0000\n",
      "Step 8 | Total: 2.1087 | CE: 2.1087 | KL: 0.0000\n",
      "Step 8 | Total: 2.8747 | CE: 2.8747 | KL: 0.0000\n",
      "Step 8 | Total: 3.6633 | CE: 3.6633 | KL: 0.0000\n",
      "Step 8 | Total: 3.2027 | CE: 3.2027 | KL: 0.0000\n",
      "Step 8 | Total: 2.0049 | CE: 2.0049 | KL: 0.0000\n",
      "Step 9 | Total: 1.7330 | CE: 1.7330 | KL: 0.0000\n",
      "Step 9 | Total: 3.0386 | CE: 3.0386 | KL: 0.0000\n",
      "Step 9 | Total: 2.5960 | CE: 2.5960 | KL: 0.0000\n",
      "Step 9 | Total: 2.3005 | CE: 2.3005 | KL: 0.0000\n",
      "Step 9 | Total: 1.0792 | CE: 1.0792 | KL: 0.0000\n",
      "Step 9 | Total: 2.3328 | CE: 2.3328 | KL: 0.0000\n",
      "Step 9 | Total: 11.0858 | CE: 11.0858 | KL: 0.0000\n",
      "Step 9 | Total: 2.9284 | CE: 2.9284 | KL: 0.0000\n",
      "Step 9 | Total: 2.9736 | CE: 2.9736 | KL: 0.0000\n",
      "Step 9 | Total: 3.0526 | CE: 3.0526 | KL: 0.0000\n",
      "Step 9 | Total: 3.0733 | CE: 3.0733 | KL: 0.0000\n",
      "Step 9 | Total: 2.5767 | CE: 2.5767 | KL: 0.0000\n",
      "Step 9 | Total: 2.3577 | CE: 2.3577 | KL: 0.0000\n",
      "Step 9 | Total: 2.5689 | CE: 2.5689 | KL: 0.0000\n",
      "Step 9 | Total: 3.6818 | CE: 3.6818 | KL: 0.0000\n",
      "Step 9 | Total: 3.5950 | CE: 3.5950 | KL: 0.0000\n",
      "Step 9 | Total: 1.7888 | CE: 1.7888 | KL: 0.0000\n",
      "Step 9 | Total: 3.1478 | CE: 3.1478 | KL: 0.0000\n",
      "Step 9 | Total: 4.0698 | CE: 4.0698 | KL: 0.0000\n",
      "Step 9 | Total: 2.1375 | CE: 2.1375 | KL: 0.0000\n",
      "Step 9 | Total: 2.6012 | CE: 2.6012 | KL: 0.0000\n",
      "Step 9 | Total: 2.8593 | CE: 2.8593 | KL: 0.0000\n",
      "Step 9 | Total: 4.2689 | CE: 4.2689 | KL: 0.0000\n",
      "Step 9 | Total: 17.3965 | CE: 17.3965 | KL: 0.0000\n",
      "Step 9 | Total: 2.5738 | CE: 2.5738 | KL: 0.0000\n",
      "Step 9 | Total: 1.9191 | CE: 1.9191 | KL: 0.0000\n",
      "Step 9 | Total: 2.2573 | CE: 2.2573 | KL: 0.0000\n",
      "Step 9 | Total: 3.6548 | CE: 3.6548 | KL: 0.0000\n",
      "Step 9 | Total: 3.2523 | CE: 3.2523 | KL: 0.0000\n",
      "Step 9 | Total: 2.8996 | CE: 2.8996 | KL: 0.0000\n",
      "Step 9 | Total: 2.4707 | CE: 2.4707 | KL: 0.0000\n",
      "Step 9 | Total: 5.1849 | CE: 5.1849 | KL: 0.0000\n",
      "Step 10 | Total: 2.9818 | CE: 2.9818 | KL: 0.0000\n",
      "Step 10 | Total: 2.4183 | CE: 2.4183 | KL: 0.0000\n",
      "Step 10 | Total: 2.0648 | CE: 2.0648 | KL: 0.0000\n",
      "Step 10 | Total: 4.7004 | CE: 4.7004 | KL: 0.0000\n",
      "Step 10 | Total: 1.7493 | CE: 1.7493 | KL: 0.0000\n",
      "Step 10 | Total: 3.7133 | CE: 3.7133 | KL: 0.0000\n",
      "Step 10 | Total: 2.3201 | CE: 2.3201 | KL: 0.0000\n",
      "Step 10 | Total: 3.3230 | CE: 3.3230 | KL: 0.0000\n",
      "Step 10 | Total: 3.7304 | CE: 3.7304 | KL: 0.0000\n",
      "Step 10 | Total: 2.9502 | CE: 2.9502 | KL: 0.0000\n",
      "Step 10 | Total: 2.3512 | CE: 2.3512 | KL: 0.0000\n",
      "Step 10 | Total: 2.3839 | CE: 2.3839 | KL: 0.0000\n",
      "Step 10 | Total: 1.6367 | CE: 1.6367 | KL: 0.0000\n",
      "Step 10 | Total: 2.8685 | CE: 2.8685 | KL: 0.0000\n",
      "Step 10 | Total: 9.2855 | CE: 9.2855 | KL: 0.0000\n",
      "Step 10 | Total: 2.9093 | CE: 2.9093 | KL: 0.0000\n",
      "Step 10 | Total: 2.1808 | CE: 2.1808 | KL: 0.0000\n",
      "Step 10 | Total: 3.1643 | CE: 3.1643 | KL: 0.0000\n",
      "Step 10 | Total: 1.8195 | CE: 1.8195 | KL: 0.0000\n",
      "Step 10 | Total: 2.3758 | CE: 2.3758 | KL: 0.0000\n",
      "Step 10 | Total: 2.4410 | CE: 2.4410 | KL: 0.0000\n",
      "Step 10 | Total: 2.4721 | CE: 2.4721 | KL: 0.0000\n",
      "Step 10 | Total: 1.7966 | CE: 1.7966 | KL: 0.0000\n",
      "Step 10 | Total: 6.1699 | CE: 6.1699 | KL: 0.0000\n",
      "Step 10 | Total: 2.3342 | CE: 2.3342 | KL: 0.0000\n",
      "Step 10 | Total: 2.4492 | CE: 2.4492 | KL: 0.0000\n",
      "Step 10 | Total: 2.7863 | CE: 2.7863 | KL: 0.0000\n",
      "Step 10 | Total: 1.9681 | CE: 1.9681 | KL: 0.0000\n",
      "Step 10 | Total: 2.3880 | CE: 2.3880 | KL: 0.0000\n",
      "Step 10 | Total: 2.3234 | CE: 2.3234 | KL: 0.0000\n",
      "Step 10 | Total: 3.8041 | CE: 3.8041 | KL: 0.0000\n",
      "Step 10 | Total: 4.3833 | CE: 4.3833 | KL: 0.0000\n",
      "Step 11 | Total: 2.7673 | CE: 2.7673 | KL: 0.0000\n",
      "Step 11 | Total: 2.5093 | CE: 2.5093 | KL: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to gemma_debug/checkpoint-12\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
      "Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"layer_types\": [\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "chat template saved in gemma_debug/checkpoint-12/chat_template.jinja\n",
      "tokenizer config file saved in gemma_debug/checkpoint-12/tokenizer_config.json\n",
      "Special tokens file saved in gemma_debug/checkpoint-12/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12 | Total: 2.3770 | CE: 2.3770 | KL: 0.0000\n",
      "Step 12 | Total: 2.5147 | CE: 2.5147 | KL: 0.0000\n",
      "Step 12 | Total: 2.8512 | CE: 2.8512 | KL: 0.0000\n",
      "Step 12 | Total: 3.5598 | CE: 3.5598 | KL: 0.0000\n",
      "Step 12 | Total: 1.9334 | CE: 1.9334 | KL: 0.0000\n",
      "Step 12 | Total: 2.5054 | CE: 2.5054 | KL: 0.0000\n",
      "Step 12 | Total: 3.6849 | CE: 3.6849 | KL: 0.0000\n",
      "Step 12 | Total: 2.1228 | CE: 2.1228 | KL: 0.0000\n",
      "Step 12 | Total: 2.5435 | CE: 2.5435 | KL: 0.0000\n",
      "Step 12 | Total: 2.7105 | CE: 2.7105 | KL: 0.0000\n",
      "Step 12 | Total: 2.5948 | CE: 2.5948 | KL: 0.0000\n",
      "Step 12 | Total: 3.6953 | CE: 3.6953 | KL: 0.0000\n",
      "Step 12 | Total: 10.8416 | CE: 10.8416 | KL: 0.0000\n",
      "Step 12 | Total: 2.0174 | CE: 2.0174 | KL: 0.0000\n",
      "Step 12 | Total: 3.1377 | CE: 3.1377 | KL: 0.0000\n",
      "Step 12 | Total: 17.3391 | CE: 17.3391 | KL: 0.0000\n",
      "Step 12 | Total: 12.2528 | CE: 12.2528 | KL: 0.0000\n",
      "Step 12 | Total: 2.8455 | CE: 2.8455 | KL: 0.0000\n",
      "Step 12 | Total: 3.7781 | CE: 3.7781 | KL: 0.0000\n",
      "Step 12 | Total: 2.0973 | CE: 2.0973 | KL: 0.0000\n",
      "Step 12 | Total: 1.8967 | CE: 1.8967 | KL: 0.0000\n",
      "Step 12 | Total: 3.7573 | CE: 3.7573 | KL: 0.0000\n",
      "Step 12 | Total: 3.7010 | CE: 3.7010 | KL: 0.0000\n",
      "Step 12 | Total: 3.2077 | CE: 3.2077 | KL: 0.0000\n",
      "Step 12 | Total: 2.1277 | CE: 2.1277 | KL: 0.0000\n",
      "Step 12 | Total: 2.3315 | CE: 2.3315 | KL: 0.0000\n",
      "Step 12 | Total: 2.1111 | CE: 2.1111 | KL: 0.0000\n",
      "Step 12 | Total: 2.2077 | CE: 2.2077 | KL: 0.0000\n",
      "Step 12 | Total: 4.6891 | CE: 4.6891 | KL: 0.0000\n",
      "Step 12 | Total: 2.3715 | CE: 2.3715 | KL: 0.0000\n",
      "Step 12 | Total: 2.4321 | CE: 2.4321 | KL: 0.0000\n",
      "Step 12 | Total: 1.5160 | CE: 1.5160 | KL: 0.0000\n",
      "Step 13 | Total: 2.1078 | CE: 2.1078 | KL: 0.0000\n",
      "Step 13 | Total: 2.7659 | CE: 2.7659 | KL: 0.0000\n",
      "Step 13 | Total: 1.7819 | CE: 1.7819 | KL: 0.0000\n",
      "Step 13 | Total: 4.2595 | CE: 4.2595 | KL: 0.0000\n",
      "Step 13 | Total: 2.4781 | CE: 2.4781 | KL: 0.0000\n",
      "Step 13 | Total: 3.5856 | CE: 3.5856 | KL: 0.0000\n",
      "Step 13 | Total: 6.1275 | CE: 6.1275 | KL: 0.0000\n",
      "Step 13 | Total: 2.4548 | CE: 2.4548 | KL: 0.0000\n",
      "Step 13 | Total: 2.5524 | CE: 2.5524 | KL: 0.0000\n",
      "Step 13 | Total: 2.3068 | CE: 2.3068 | KL: 0.0000\n",
      "Step 13 | Total: 2.2511 | CE: 2.2511 | KL: 0.0000\n",
      "Step 13 | Total: 2.8390 | CE: 2.8390 | KL: 0.0000\n",
      "Step 13 | Total: 1.9568 | CE: 1.9568 | KL: 0.0000\n",
      "Step 13 | Total: 2.3174 | CE: 2.3174 | KL: 0.0000\n",
      "Step 13 | Total: 3.5898 | CE: 3.5898 | KL: 0.0000\n",
      "Step 13 | Total: 1.6170 | CE: 1.6170 | KL: 0.0000\n",
      "Step 13 | Total: 2.5571 | CE: 2.5571 | KL: 0.0000\n",
      "Step 13 | Total: 6.6426 | CE: 6.6426 | KL: 0.0000\n",
      "Step 13 | Total: 2.4597 | CE: 2.4597 | KL: 0.0000\n",
      "Step 13 | Total: 2.9449 | CE: 2.9449 | KL: 0.0000\n",
      "Step 13 | Total: 3.9419 | CE: 3.9419 | KL: 0.0000\n",
      "Step 13 | Total: 3.7903 | CE: 3.7903 | KL: 0.0000\n",
      "Step 13 | Total: 2.9646 | CE: 2.9646 | KL: 0.0000\n",
      "Step 13 | Total: 2.4652 | CE: 2.4652 | KL: 0.0000\n",
      "Step 13 | Total: 1.7837 | CE: 1.7837 | KL: 0.0000\n",
      "Step 13 | Total: 2.4970 | CE: 2.4970 | KL: 0.0000\n",
      "Step 13 | Total: 2.9865 | CE: 2.9865 | KL: 0.0000\n",
      "Step 13 | Total: 2.7422 | CE: 2.7422 | KL: 0.0000\n",
      "Step 13 | Total: 1.7258 | CE: 1.7258 | KL: 0.0000\n",
      "Step 13 | Total: 2.5690 | CE: 2.5690 | KL: 0.0000\n",
      "Step 13 | Total: 2.4374 | CE: 2.4374 | KL: 0.0000\n",
      "Step 13 | Total: 2.2864 | CE: 2.2864 | KL: 0.0000\n",
      "Step 14 | Total: 3.7117 | CE: 3.7117 | KL: 0.0000\n",
      "Step 14 | Total: 4.2352 | CE: 4.2352 | KL: 0.0000\n",
      "Step 14 | Total: 2.6531 | CE: 2.6531 | KL: 0.0000\n",
      "Step 14 | Total: 4.3875 | CE: 4.3875 | KL: 0.0000\n",
      "Step 14 | Total: 2.2781 | CE: 2.2781 | KL: 0.0000\n",
      "Step 14 | Total: 5.1110 | CE: 5.1110 | KL: 0.0000\n",
      "Step 14 | Total: 2.5416 | CE: 2.5416 | KL: 0.0000\n",
      "Step 14 | Total: 2.8442 | CE: 2.8442 | KL: 0.0000\n",
      "Step 14 | Total: 9.1670 | CE: 9.1670 | KL: 0.0000\n",
      "Step 14 | Total: 3.6228 | CE: 3.6228 | KL: 0.0000\n",
      "Step 14 | Total: 5.0894 | CE: 5.0894 | KL: 0.0000\n",
      "Step 14 | Total: 2.4206 | CE: 2.4206 | KL: 0.0000\n",
      "Step 14 | Total: 2.5509 | CE: 2.5509 | KL: 0.0000\n",
      "Step 14 | Total: 3.0218 | CE: 3.0218 | KL: 0.0000\n",
      "Step 14 | Total: 1.7156 | CE: 1.7156 | KL: 0.0000\n",
      "Step 14 | Total: 6.1954 | CE: 6.1954 | KL: 0.0000\n",
      "Step 14 | Total: 4.6772 | CE: 4.6772 | KL: 0.0000\n",
      "Step 14 | Total: 1.0711 | CE: 1.0711 | KL: 0.0000\n",
      "Step 14 | Total: 2.9796 | CE: 2.9796 | KL: 0.0000\n",
      "Step 14 | Total: 3.6331 | CE: 3.6331 | KL: 0.0000\n",
      "Step 14 | Total: 1.9703 | CE: 1.9703 | KL: 0.0000\n",
      "Step 14 | Total: 2.5962 | CE: 2.5962 | KL: 0.0000\n",
      "Step 14 | Total: 3.1446 | CE: 3.1446 | KL: 0.0000\n",
      "Step 14 | Total: 1.9375 | CE: 1.9375 | KL: 0.0000\n",
      "Step 14 | Total: 4.5684 | CE: 4.5684 | KL: 0.0000\n",
      "Step 14 | Total: 1.8514 | CE: 1.8514 | KL: 0.0000\n",
      "Step 14 | Total: 1.9122 | CE: 1.9122 | KL: 0.0000\n",
      "Step 14 | Total: 2.5888 | CE: 2.5888 | KL: 0.0000\n",
      "Step 14 | Total: 1.4457 | CE: 1.4457 | KL: 0.0000\n",
      "Step 14 | Total: 2.9715 | CE: 2.9715 | KL: 0.0000\n",
      "Step 14 | Total: 2.6476 | CE: 2.6476 | KL: 0.0000\n",
      "Step 14 | Total: 1.9823 | CE: 1.9823 | KL: 0.0000\n",
      "Step 15 | Total: 3.3203 | CE: 3.3203 | KL: 0.0000\n",
      "Step 15 | Total: 2.0475 | CE: 2.0475 | KL: 0.0000\n",
      "Step 15 | Total: 2.6114 | CE: 2.6114 | KL: 0.0000\n",
      "Step 15 | Total: 1.7115 | CE: 1.7115 | KL: 0.0000\n",
      "Step 15 | Total: 4.3542 | CE: 4.3542 | KL: 0.0000\n",
      "Step 15 | Total: 2.9041 | CE: 2.9041 | KL: 0.0000\n",
      "Step 15 | Total: 1.7680 | CE: 1.7680 | KL: 0.0000\n",
      "Step 15 | Total: 2.3405 | CE: 2.3405 | KL: 0.0000\n",
      "Step 15 | Total: 1.8135 | CE: 1.8135 | KL: 0.0000\n",
      "Step 15 | Total: 4.3027 | CE: 4.3027 | KL: 0.0000\n",
      "Step 15 | Total: 2.6714 | CE: 2.6714 | KL: 0.0000\n",
      "Step 15 | Total: 4.0210 | CE: 4.0210 | KL: 0.0000\n",
      "Step 15 | Total: 1.8609 | CE: 1.8609 | KL: 0.0000\n",
      "Step 15 | Total: 3.0810 | CE: 3.0810 | KL: 0.0000\n",
      "Step 15 | Total: 2.3740 | CE: 2.3740 | KL: 0.0000\n",
      "Step 15 | Total: 1.9614 | CE: 1.9614 | KL: 0.0000\n",
      "Step 15 | Total: 2.5501 | CE: 2.5501 | KL: 0.0000\n",
      "Step 15 | Total: 3.0781 | CE: 3.0781 | KL: 0.0000\n",
      "Step 15 | Total: 2.1160 | CE: 2.1160 | KL: 0.0000\n",
      "Step 15 | Total: 2.9921 | CE: 2.9921 | KL: 0.0000\n",
      "Step 15 | Total: 2.3708 | CE: 2.3708 | KL: 0.0000\n",
      "Step 15 | Total: 2.3623 | CE: 2.3623 | KL: 0.0000\n",
      "Step 15 | Total: 2.4520 | CE: 2.4520 | KL: 0.0000\n",
      "Step 15 | Total: 4.7246 | CE: 4.7246 | KL: 0.0000\n",
      "Step 15 | Total: 1.8649 | CE: 1.8649 | KL: 0.0000\n",
      "Step 15 | Total: 12.2802 | CE: 12.2802 | KL: 0.0000\n",
      "Step 15 | Total: 2.3511 | CE: 2.3511 | KL: 0.0000\n",
      "Step 15 | Total: 2.1673 | CE: 2.1673 | KL: 0.0000\n",
      "Step 15 | Total: 3.9672 | CE: 3.9672 | KL: 0.0000\n",
      "Step 15 | Total: 1.9575 | CE: 1.9575 | KL: 0.0000\n",
      "Step 15 | Total: 3.1151 | CE: 3.1151 | KL: 0.0000\n",
      "Step 15 | Total: 17.3016 | CE: 17.3016 | KL: 0.0000\n",
      "Step 16 | Total: 2.0503 | CE: 2.0503 | KL: 0.0000\n",
      "Step 16 | Total: 3.6213 | CE: 3.6213 | KL: 0.0000\n",
      "Step 16 | Total: 3.4781 | CE: 3.4781 | KL: 0.0000\n",
      "Step 16 | Total: 1.7700 | CE: 1.7700 | KL: 0.0000\n",
      "Step 16 | Total: 1.6459 | CE: 1.6459 | KL: 0.0000\n",
      "Step 16 | Total: 2.4048 | CE: 2.4048 | KL: 0.0000\n",
      "Step 16 | Total: 2.1147 | CE: 2.1147 | KL: 0.0000\n",
      "Step 16 | Total: 2.5919 | CE: 2.5919 | KL: 0.0000\n",
      "Step 16 | Total: 3.6004 | CE: 3.6004 | KL: 0.0000\n",
      "Step 16 | Total: 3.0095 | CE: 3.0095 | KL: 0.0000\n",
      "Step 16 | Total: 2.5874 | CE: 2.5874 | KL: 0.0000\n",
      "Step 16 | Total: 3.1611 | CE: 3.1611 | KL: 0.0000\n",
      "Step 16 | Total: 3.5211 | CE: 3.5211 | KL: 0.0000\n",
      "Step 16 | Total: 2.1399 | CE: 2.1399 | KL: 0.0000\n",
      "Step 16 | Total: 2.8705 | CE: 2.8705 | KL: 0.0000\n",
      "Step 16 | Total: 2.0597 | CE: 2.0597 | KL: 0.0000\n",
      "Step 16 | Total: 1.4972 | CE: 1.4972 | KL: 0.0000\n",
      "Step 16 | Total: 2.3522 | CE: 2.3522 | KL: 0.0000\n",
      "Step 16 | Total: 4.0219 | CE: 4.0219 | KL: 0.0000\n",
      "Step 16 | Total: 2.8732 | CE: 2.8732 | KL: 0.0000\n",
      "Step 16 | Total: 2.9162 | CE: 2.9162 | KL: 0.0000\n",
      "Step 16 | Total: 1.8384 | CE: 1.8384 | KL: 0.0000\n",
      "Step 16 | Total: 2.8608 | CE: 2.8608 | KL: 0.0000\n",
      "Step 16 | Total: 2.5049 | CE: 2.5049 | KL: 0.0000\n",
      "Step 16 | Total: 1.5733 | CE: 1.5733 | KL: 0.0000\n",
      "Step 16 | Total: 1.9188 | CE: 1.9188 | KL: 0.0000\n",
      "Step 16 | Total: 1.5090 | CE: 1.5090 | KL: 0.0000\n",
      "Step 16 | Total: 2.1200 | CE: 2.1200 | KL: 0.0000\n",
      "Step 16 | Total: 2.3042 | CE: 2.3042 | KL: 0.0000\n",
      "Step 16 | Total: 2.3124 | CE: 2.3124 | KL: 0.0000\n",
      "Step 16 | Total: 2.7488 | CE: 2.7488 | KL: 0.0000\n",
      "Step 16 | Total: 2.3963 | CE: 2.3963 | KL: 0.0000\n",
      "Step 17 | Total: 2.2534 | CE: 2.2534 | KL: 0.0000\n",
      "Step 17 | Total: 3.5515 | CE: 3.5515 | KL: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to gemma_debug/checkpoint-18\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
      "Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"layer_types\": [\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "chat template saved in gemma_debug/checkpoint-18/chat_template.jinja\n",
      "tokenizer config file saved in gemma_debug/checkpoint-18/tokenizer_config.json\n",
      "Special tokens file saved in gemma_debug/checkpoint-18/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18 | Total: 3.6113 | CE: 3.6113 | KL: 0.0000\n",
      "Step 18 | Total: 2.6285 | CE: 2.6285 | KL: 0.0000\n",
      "Step 18 | Total: 2.0411 | CE: 2.0411 | KL: 0.0000\n",
      "Step 18 | Total: 1.0648 | CE: 1.0648 | KL: 0.0000\n",
      "Step 18 | Total: 2.9289 | CE: 2.9289 | KL: 0.0000\n",
      "Step 18 | Total: 2.3560 | CE: 2.3560 | KL: 0.0000\n",
      "Step 18 | Total: 2.8110 | CE: 2.8110 | KL: 0.0000\n",
      "Step 18 | Total: 1.7637 | CE: 1.7637 | KL: 0.0000\n",
      "Step 18 | Total: 2.2415 | CE: 2.2415 | KL: 0.0000\n",
      "Step 18 | Total: 2.6291 | CE: 2.6291 | KL: 0.0000\n",
      "Step 18 | Total: 2.2798 | CE: 2.2798 | KL: 0.0000\n",
      "Step 18 | Total: 1.5697 | CE: 1.5697 | KL: 0.0000\n",
      "Step 18 | Total: 1.4966 | CE: 1.4966 | KL: 0.0000\n",
      "Step 18 | Total: 1.8671 | CE: 1.8671 | KL: 0.0000\n",
      "Step 18 | Total: 2.5857 | CE: 2.5857 | KL: 0.0000\n",
      "Step 18 | Total: 2.0545 | CE: 2.0545 | KL: 0.0000\n",
      "Step 18 | Total: 2.4964 | CE: 2.4964 | KL: 0.0000\n",
      "Step 18 | Total: 2.4456 | CE: 2.4456 | KL: 0.0000\n",
      "Step 18 | Total: 3.1110 | CE: 3.1110 | KL: 0.0000\n",
      "Step 18 | Total: 2.9714 | CE: 2.9714 | KL: 0.0000\n",
      "Step 18 | Total: 2.1669 | CE: 2.1669 | KL: 0.0000\n",
      "Step 18 | Total: 1.7611 | CE: 1.7611 | KL: 0.0000\n",
      "Step 18 | Total: 1.7669 | CE: 1.7669 | KL: 0.0000\n",
      "Step 18 | Total: 3.5414 | CE: 3.5414 | KL: 0.0000\n",
      "Step 18 | Total: 6.1480 | CE: 6.1480 | KL: 0.0000\n",
      "Step 18 | Total: 2.3079 | CE: 2.3079 | KL: 0.0000\n",
      "Step 18 | Total: 2.6699 | CE: 2.6699 | KL: 0.0000\n",
      "Step 18 | Total: 4.5882 | CE: 4.5882 | KL: 0.0000\n",
      "Step 18 | Total: 2.0976 | CE: 2.0976 | KL: 0.0000\n",
      "Step 18 | Total: 1.7802 | CE: 1.7802 | KL: 0.0000\n",
      "Step 18 | Total: 1.6055 | CE: 1.6055 | KL: 0.0000\n",
      "Step 18 | Total: 2.1011 | CE: 2.1011 | KL: 0.0000\n",
      "Step 19 | Total: 1.8512 | CE: 1.8512 | KL: 0.0000\n",
      "Step 19 | Total: 2.4196 | CE: 2.4196 | KL: 0.0000\n",
      "Step 19 | Total: 3.1468 | CE: 3.1468 | KL: 0.0000\n",
      "Step 19 | Total: 3.0678 | CE: 3.0678 | KL: 0.0000\n",
      "Step 19 | Total: 2.9837 | CE: 2.9837 | KL: 0.0000\n",
      "Step 19 | Total: 3.1511 | CE: 3.1511 | KL: 0.0000\n",
      "Step 19 | Total: 9.0775 | CE: 9.0775 | KL: 0.0000\n",
      "Step 19 | Total: 2.1928 | CE: 2.1928 | KL: 0.0000\n",
      "Step 19 | Total: 5.0379 | CE: 5.0379 | KL: 0.0000\n",
      "Step 19 | Total: 3.4900 | CE: 3.4900 | KL: 0.0000\n",
      "Step 19 | Total: 3.5913 | CE: 3.5913 | KL: 0.0000\n",
      "Step 19 | Total: 2.9528 | CE: 2.9528 | KL: 0.0000\n",
      "Step 19 | Total: 3.5300 | CE: 3.5300 | KL: 0.0000\n",
      "Step 19 | Total: 12.1320 | CE: 12.1320 | KL: 0.0000\n",
      "Step 19 | Total: 2.3400 | CE: 2.3400 | KL: 0.0000\n",
      "Step 19 | Total: 1.9247 | CE: 1.9247 | KL: 0.0000\n",
      "Step 19 | Total: 2.5804 | CE: 2.5804 | KL: 0.0000\n",
      "Step 19 | Total: 3.5708 | CE: 3.5708 | KL: 0.0000\n",
      "Step 19 | Total: 17.1464 | CE: 17.1464 | KL: 0.0000\n",
      "Step 19 | Total: 3.9985 | CE: 3.9985 | KL: 0.0000\n",
      "Step 19 | Total: 2.3077 | CE: 2.3077 | KL: 0.0000\n",
      "Step 19 | Total: 1.4297 | CE: 1.4297 | KL: 0.0000\n",
      "Step 19 | Total: 3.7199 | CE: 3.7199 | KL: 0.0000\n",
      "Step 19 | Total: 5.0430 | CE: 5.0430 | KL: 0.0000\n",
      "Step 19 | Total: 1.9486 | CE: 1.9486 | KL: 0.0000\n",
      "Step 19 | Total: 2.3521 | CE: 2.3521 | KL: 0.0000\n",
      "Step 19 | Total: 3.1085 | CE: 3.1085 | KL: 0.0000\n",
      "Step 19 | Total: 4.6443 | CE: 4.6443 | KL: 0.0000\n",
      "Step 19 | Total: 2.4483 | CE: 2.4483 | KL: 0.0000\n",
      "Step 19 | Total: 2.4957 | CE: 2.4957 | KL: 0.0000\n",
      "Step 19 | Total: 6.5274 | CE: 6.5274 | KL: 0.0000\n",
      "Step 19 | Total: 2.0944 | CE: 2.0944 | KL: 0.0000\n",
      "Step 20 | Total: 2.1105 | CE: 2.1105 | KL: 0.0000\n",
      "Step 20 | Total: 2.5792 | CE: 2.5792 | KL: 0.0000\n",
      "Step 20 | Total: 3.7418 | CE: 3.7418 | KL: 0.0000\n",
      "Step 20 | Total: 1.8352 | CE: 1.8352 | KL: 0.0000\n",
      "Step 20 | Total: 2.9141 | CE: 2.9141 | KL: 0.0000\n",
      "Step 20 | Total: 4.1841 | CE: 4.1841 | KL: 0.0000\n",
      "Step 20 | Total: 1.9204 | CE: 1.9204 | KL: 0.0000\n",
      "Step 20 | Total: 2.5449 | CE: 2.5449 | KL: 0.0000\n",
      "Step 20 | Total: 3.5437 | CE: 3.5437 | KL: 0.0000\n",
      "Step 20 | Total: 3.4567 | CE: 3.4567 | KL: 0.0000\n",
      "Step 20 | Total: 6.0125 | CE: 6.0125 | KL: 0.0000\n",
      "Step 20 | Total: 3.9908 | CE: 3.9908 | KL: 0.0000\n",
      "Step 20 | Total: 4.6686 | CE: 4.6686 | KL: 0.0000\n",
      "Step 20 | Total: 3.6149 | CE: 3.6149 | KL: 0.0000\n",
      "Step 20 | Total: 2.2354 | CE: 2.2354 | KL: 0.0000\n",
      "Step 20 | Total: 1.5058 | CE: 1.5058 | KL: 0.0000\n",
      "Step 20 | Total: 2.9698 | CE: 2.9698 | KL: 0.0000\n",
      "Step 20 | Total: 1.9531 | CE: 1.9531 | KL: 0.0000\n",
      "Step 20 | Total: 2.3450 | CE: 2.3450 | KL: 0.0000\n",
      "Step 20 | Total: 2.8837 | CE: 2.8837 | KL: 0.0000\n",
      "Step 20 | Total: 2.4639 | CE: 2.4639 | KL: 0.0000\n",
      "Step 20 | Total: 4.5192 | CE: 4.5192 | KL: 0.0000\n",
      "Step 20 | Total: 2.4473 | CE: 2.4473 | KL: 0.0000\n",
      "Step 20 | Total: 2.3284 | CE: 2.3284 | KL: 0.0000\n",
      "Step 20 | Total: 2.8354 | CE: 2.8354 | KL: 0.0000\n",
      "Step 20 | Total: 2.3409 | CE: 2.3409 | KL: 0.0000\n",
      "Step 20 | Total: 2.5888 | CE: 2.5888 | KL: 0.0000\n",
      "Step 20 | Total: 2.1151 | CE: 2.1151 | KL: 0.0000\n",
      "Step 20 | Total: 1.8944 | CE: 1.8944 | KL: 0.0000\n",
      "Step 20 | Total: 2.5373 | CE: 2.5373 | KL: 0.0000\n",
      "Step 20 | Total: 2.7407 | CE: 2.7407 | KL: 0.0000\n",
      "Step 20 | Total: 17.1889 | CE: 17.1889 | KL: 0.0000\n",
      "Step 21 | Total: 2.2998 | CE: 2.2998 | KL: 0.0000\n",
      "Step 21 | Total: 2.2706 | CE: 2.2706 | KL: 0.0000\n",
      "Step 21 | Total: 2.9338 | CE: 2.9338 | KL: 0.0000\n",
      "Step 21 | Total: 1.7046 | CE: 1.7046 | KL: 0.0000\n",
      "Step 21 | Total: 3.1132 | CE: 3.1132 | KL: 0.0000\n",
      "Step 21 | Total: 2.3529 | CE: 2.3529 | KL: 0.0000\n",
      "Step 21 | Total: 4.3215 | CE: 4.3215 | KL: 0.0000\n",
      "Step 21 | Total: 2.7425 | CE: 2.7425 | KL: 0.0000\n",
      "Step 21 | Total: 2.0910 | CE: 2.0910 | KL: 0.0000\n",
      "Step 21 | Total: 2.5450 | CE: 2.5450 | KL: 0.0000\n",
      "Step 21 | Total: 2.3971 | CE: 2.3971 | KL: 0.0000\n",
      "Step 21 | Total: 4.3609 | CE: 4.3609 | KL: 0.0000\n",
      "Step 21 | Total: 1.9319 | CE: 1.9319 | KL: 0.0000\n",
      "Step 21 | Total: 12.0781 | CE: 12.0781 | KL: 0.0000\n",
      "Step 21 | Total: 1.7200 | CE: 1.7200 | KL: 0.0000\n",
      "Step 21 | Total: 2.0285 | CE: 2.0285 | KL: 0.0000\n",
      "Step 21 | Total: 2.8555 | CE: 2.8555 | KL: 0.0000\n",
      "Step 21 | Total: 3.6641 | CE: 3.6641 | KL: 0.0000\n",
      "Step 21 | Total: 1.8315 | CE: 1.8315 | KL: 0.0000\n",
      "Step 21 | Total: 3.9033 | CE: 3.9033 | KL: 0.0000\n",
      "Step 21 | Total: 1.8100 | CE: 1.8100 | KL: 0.0000\n",
      "Step 21 | Total: 2.5282 | CE: 2.5282 | KL: 0.0000\n",
      "Step 21 | Total: 2.1041 | CE: 2.1041 | KL: 0.0000\n",
      "Step 21 | Total: 3.6298 | CE: 3.6298 | KL: 0.0000\n",
      "Step 21 | Total: 2.0036 | CE: 2.0036 | KL: 0.0000\n",
      "Step 21 | Total: 2.9087 | CE: 2.9087 | KL: 0.0000\n",
      "Step 21 | Total: 3.6158 | CE: 3.6158 | KL: 0.0000\n",
      "Step 21 | Total: 1.9153 | CE: 1.9153 | KL: 0.0000\n",
      "Step 21 | Total: 2.6855 | CE: 2.6855 | KL: 0.0000\n",
      "Step 21 | Total: 1.6367 | CE: 1.6367 | KL: 0.0000\n",
      "Step 21 | Total: 1.9556 | CE: 1.9556 | KL: 0.0000\n",
      "Step 21 | Total: 10.5715 | CE: 10.5715 | KL: 0.0000\n",
      "Step 22 | Total: 3.6918 | CE: 3.6918 | KL: 0.0000\n",
      "Step 22 | Total: 2.1060 | CE: 2.1060 | KL: 0.0000\n",
      "Step 22 | Total: 2.8296 | CE: 2.8296 | KL: 0.0000\n",
      "Step 22 | Total: 2.7137 | CE: 2.7137 | KL: 0.0000\n",
      "Step 22 | Total: 3.8830 | CE: 3.8830 | KL: 0.0000\n",
      "Step 22 | Total: 2.5823 | CE: 2.5823 | KL: 0.0000\n",
      "Step 22 | Total: 2.4618 | CE: 2.4618 | KL: 0.0000\n",
      "Step 22 | Total: 2.3149 | CE: 2.3149 | KL: 0.0000\n",
      "Step 22 | Total: 2.2654 | CE: 2.2654 | KL: 0.0000\n",
      "Step 22 | Total: 2.4068 | CE: 2.4068 | KL: 0.0000\n",
      "Step 22 | Total: 4.2391 | CE: 4.2391 | KL: 0.0000\n",
      "Step 22 | Total: 2.1310 | CE: 2.1310 | KL: 0.0000\n",
      "Step 22 | Total: 2.8520 | CE: 2.8520 | KL: 0.0000\n",
      "Step 22 | Total: 2.4725 | CE: 2.4725 | KL: 0.0000\n",
      "Step 22 | Total: 2.5094 | CE: 2.5094 | KL: 0.0000\n",
      "Step 22 | Total: 2.3378 | CE: 2.3378 | KL: 0.0000\n",
      "Step 22 | Total: 2.9870 | CE: 2.9870 | KL: 0.0000\n",
      "Step 22 | Total: 1.9589 | CE: 1.9589 | KL: 0.0000\n",
      "Step 22 | Total: 1.8609 | CE: 1.8609 | KL: 0.0000\n",
      "Step 22 | Total: 2.3817 | CE: 2.3817 | KL: 0.0000\n",
      "Step 22 | Total: 2.8319 | CE: 2.8319 | KL: 0.0000\n",
      "Step 22 | Total: 2.4988 | CE: 2.4988 | KL: 0.0000\n",
      "Step 22 | Total: 3.6620 | CE: 3.6620 | KL: 0.0000\n",
      "Step 22 | Total: 3.0700 | CE: 3.0700 | KL: 0.0000\n",
      "Step 22 | Total: 4.1967 | CE: 4.1967 | KL: 0.0000\n",
      "Step 22 | Total: 2.8486 | CE: 2.8486 | KL: 0.0000\n",
      "Step 22 | Total: 1.5008 | CE: 1.5008 | KL: 0.0000\n",
      "Step 22 | Total: 2.4012 | CE: 2.4012 | KL: 0.0000\n",
      "Step 22 | Total: 2.5300 | CE: 2.5300 | KL: 0.0000\n",
      "Step 22 | Total: 2.5896 | CE: 2.5896 | KL: 0.0000\n",
      "Step 22 | Total: 3.3059 | CE: 3.3059 | KL: 0.0000\n",
      "Step 22 | Total: 1.6842 | CE: 1.6842 | KL: 0.0000\n",
      "Step 23 | Total: 3.6057 | CE: 3.6057 | KL: 0.0000\n",
      "Step 23 | Total: 2.4425 | CE: 2.4425 | KL: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to gemma_debug/checkpoint-24\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
      "Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"layer_types\": [\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "chat template saved in gemma_debug/checkpoint-24/chat_template.jinja\n",
      "tokenizer config file saved in gemma_debug/checkpoint-24/tokenizer_config.json\n",
      "Special tokens file saved in gemma_debug/checkpoint-24/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
      "Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"layer_types\": [\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ Guardando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chat template saved in qwen_result/chat_template.jinja\n",
      "tokenizer config file saved in qwen_result/tokenizer_config.json\n",
      "Special tokens file saved in qwen_result/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('qwen_result/tokenizer_config.json',\n",
       " 'qwen_result/special_tokens_map.json',\n",
       " 'qwen_result/chat_template.jinja',\n",
       " 'qwen_result/vocab.json',\n",
       " 'qwen_result/merges.txt',\n",
       " 'qwen_result/added_tokens.json',\n",
       " 'qwen_result/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import warnings\n",
    "import gc\n",
    "from dataclasses import dataclass\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, AutoTokenizer, DataCollatorForSeq2Seq,\n",
    "    BitsAndBytesConfig, AutoModel, TrainingArguments, Trainer\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers.utils import logging\n",
    "\n",
    "# 0. CONFIGURACIÃ“N\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.set_verbosity_info()\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸš‘ MODO RESCATE: ANTI-NAN + DIAGNÃ“STICO DE DATOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "MODELO = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "num_train_epochs = 4\n",
    "# ğŸ”¥ CAMBIO 1: Apagamos KL para la primera prueba. Si esto entrena, el problema era el Teacher.\n",
    "KL_WEIGHT = 0.0\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "# 1. CARGA DE MODELO\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODELO, quantization_config=bnb_config, device_map=\"auto\", trust_remote_code=True\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODELO)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# 2. LORA\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.enable_input_require_grads()\n",
    "peft_config = LoraConfig(\n",
    "    r=8, lora_alpha=16, lora_dropout=0.05, # Bajamos R para estabilidad\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\", bias=\"none\"\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# 3. TEACHER (Cargado pero desconectado por ahora si KL=0)\n",
    "ref_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODELO, quantization_config=bnb_config, device_map=\"auto\", trust_remote_code=True\n",
    ")\n",
    "ref_model.eval()\n",
    "\n",
    "# 4. PREPROCESAMIENTO (VERIFICACIÃ“N DE ETIQUETAS)\n",
    "def preprocess_function(examples, max_length=1024):\n",
    "    model_inputs = {\"input_ids\": [], \"attention_mask\": [], \"labels\": [], \"source_texts\": []}\n",
    "    for prompt, response in zip(examples[\"prompt\"], examples[\"response\"]):\n",
    "        if not response: continue\n",
    "\n",
    "        # Tokenizar\n",
    "        p_ids = tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n",
    "        r_ids = tokenizer(response, add_special_tokens=False)[\"input_ids\"]\n",
    "\n",
    "        if len(p_ids) >= max_length: continue\n",
    "        if len(r_ids) == 0: continue\n",
    "\n",
    "        # EOS Token\n",
    "        if r_ids[-1] != tokenizer.eos_token_id: r_ids.append(tokenizer.eos_token_id)\n",
    "\n",
    "        full_ids = p_ids + r_ids\n",
    "        if len(full_ids) > max_length:\n",
    "            full_ids = full_ids[:max_length]\n",
    "            if len(full_ids) > len(p_ids): full_ids[-1] = tokenizer.eos_token_id\n",
    "\n",
    "        # Labels: -100 en prompt\n",
    "        labels = [-100] * len(p_ids) + full_ids[len(p_ids):]\n",
    "        attention_mask = [1] * len(full_ids)\n",
    "\n",
    "        # Source text dummy\n",
    "        src = \"text\"\n",
    "\n",
    "        model_inputs[\"input_ids\"].append(full_ids)\n",
    "        model_inputs[\"attention_mask\"].append(attention_mask)\n",
    "        model_inputs[\"labels\"].append(labels)\n",
    "        model_inputs[\"source_texts\"].append(src)\n",
    "    return model_inputs\n",
    "\n",
    "print(\"ğŸ”„ Tokenizando...\")\n",
    "tokenized_train = hf_ds[\"train\"].map(preprocess_function, batched=True, remove_columns=hf_ds[\"train\"].column_names)\n",
    "tokenized_train = tokenized_train.filter(lambda x: len(x['input_ids']) > 0)\n",
    "\n",
    "# ğŸ”¥ DIAGNÃ“STICO DE DATOS (IMPORTANTE)\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"ğŸ§ INSPECCIÃ“N DE DATOS\")\n",
    "sample = tokenized_train[0]\n",
    "valid_labels = [l for l in sample['labels'] if l != -100]\n",
    "print(f\"Tokens Totales: {len(sample['input_ids'])}\")\n",
    "print(f\"Tokens VÃ¡lidos (Labels): {len(valid_labels)}\")\n",
    "if len(valid_labels) == 0:\n",
    "    print(\"âŒ ERROR: Tus datos estÃ¡n generando labels vacÃ­os. El modelo recibe todo -100.\")\n",
    "else:\n",
    "    print(\"âœ… DATOS OK. El modelo tiene quÃ© aprender.\")\n",
    "print(\"=\"*40 + \"\\n\")\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorWithSourceTexts:\n",
    "    tokenizer: AutoTokenizer\n",
    "    def __call__(self, features):\n",
    "        source_texts = [f.get(\"source_texts\", \"\") for f in features]\n",
    "        cleaned = [{k: v for k, v in f.items() if k != \"source_texts\"} for f in features]\n",
    "        batch = DataCollatorForSeq2Seq(self.tokenizer, padding=True)(cleaned)\n",
    "        batch[\"metadata\"] = {\"source_texts\": source_texts}\n",
    "        return batch\n",
    "\n",
    "# 5. LOSS BLINDADA (AQUÃ ESTÃ LA SOLUCIÃ“N AL NAN)\n",
    "class CosineAlignedLoss(nn.Module):\n",
    "    def __init__(self, kl_weight=0, ref_model=None):\n",
    "        super().__init__()\n",
    "        self.ce = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "        self.kl_weight = kl_weight\n",
    "        self.ref_model = ref_model\n",
    "\n",
    "    def forward(self, outputs, labels, inputs=None, **kwargs):\n",
    "        # 1. Obtener Logits\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # ğŸ”¥ FIX ANTI-NAN: Convertir a Float32 ANTES de calcular nada\n",
    "        # BFloat16 puede causar overflow en log_softmax con Gemma\n",
    "        logits = logits.float()\n",
    "\n",
    "        shift_logits = logits[..., :-1, :].contiguous()\n",
    "        shift_labels = labels[..., 1:].contiguous()\n",
    "\n",
    "        # 2. Cross Entropy Segura\n",
    "        ce_loss = self.ce(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "\n",
    "        # 3. KL Divergence Segura\n",
    "        kl_loss_val = torch.tensor(0.0, device=logits.device)\n",
    "\n",
    "        if self.kl_weight > 0 and self.ref_model:\n",
    "            with torch.no_grad():\n",
    "                ref_out = self.ref_model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "                # Teacher logits tambiÃ©n a Float32\n",
    "                ref_logits = ref_out.logits.float()\n",
    "\n",
    "            # Log Softmax Seguro\n",
    "            stud_log_probs = F.log_softmax(logits, dim=-1)\n",
    "            teach_probs = F.softmax(ref_logits, dim=-1)\n",
    "\n",
    "            kl_loss_val = F.kl_div(stud_log_probs, teach_probs, reduction=\"batchmean\")\n",
    "\n",
    "            # Ãšltima defensa: si KL sale NaN, lo forzamos a 0\n",
    "            if torch.isnan(kl_loss_val) or torch.isinf(kl_loss_val):\n",
    "                kl_loss_val = torch.tensor(0.0, device=logits.device)\n",
    "\n",
    "        total_loss = ce_loss + (self.kl_weight * kl_loss_val)\n",
    "        return total_loss, ce_loss, kl_loss_val\n",
    "\n",
    "class CosineAlignedTrainer(Trainer):\n",
    "    def __init__(self, kl_weight=0, ref_model=None, **kwargs):\n",
    "        processing_class = kwargs.pop('tokenizer', None)\n",
    "        super().__init__(processing_class=processing_class, **kwargs)\n",
    "        self.custom_loss = CosineAlignedLoss(kl_weight=kl_weight, ref_model=ref_model)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        fwd_inputs = {k: v for k, v in inputs.items() if k in [\"input_ids\", \"attention_mask\", \"labels\"]}\n",
    "        outputs = model(**fwd_inputs)\n",
    "        loss, ce, kl = self.custom_loss(outputs, inputs[\"labels\"], inputs=fwd_inputs)\n",
    "\n",
    "        # Log manual\n",
    "        if self.state.global_step % 1 == 0:\n",
    "            print(f\"Step {self.state.global_step} | Total: {loss.item():.4f} | CE: {ce.item():.4f} | KL: {kl.item():.4f}\")\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# 6. EJECUCIÃ“N\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"gemma_debug\",\n",
    "    per_device_train_batch_size=1, # Obligatorio batch 1 para memoria\n",
    "    gradient_accumulation_steps=32,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    max_grad_norm=0.5, # Clipping agresivo para evitar NaN\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=5,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    bf16=True,\n",
    "    logging_steps=1,\n",
    "    report_to=\"none\",\n",
    "    save_strategy=\"epoch\",\n",
    "    disable_tqdm=False,\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "trainer = CosineAlignedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithSourceTexts(tokenizer),\n",
    "    kl_weight=KL_WEIGHT,\n",
    "    ref_model=ref_model\n",
    ")\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "print(\"\\nğŸš€ INICIANDO ENTRENAMIENTO...\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\nğŸ’¾ Guardando...\")\n",
    "model.save_pretrained(\"qwen_result\")\n",
    "tokenizer.save_pretrained(\"qwen_result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mL4OFHLf8WBf",
    "outputId": "770a83e2-b5df-40fd-a4b1-ad55c65eb254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original size:\n",
      "   Train: 1800\n",
      "   Test: 200\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset original size:\")\n",
    "print(f\"   Train: {len(hf_ds['train'])}\")\n",
    "print(f\"   Test: {len(hf_ds['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wTP1-5ZC-XgC",
    "outputId": "d2b61cda-52e0-424f-94b9-aab5f3705433"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       loss  grad_norm  learning_rate     epoch  step  train_runtime  \\\n",
      "0  118.5287  89.654404       0.000000  0.197531     1            NaN   \n",
      "1  107.5396  64.302963       0.000002  0.395062     2            NaN   \n",
      "2   82.5701  47.223557       0.000004  0.592593     3            NaN   \n",
      "3  108.7308  70.788849       0.000006  0.790123     4            NaN   \n",
      "4  105.1576  83.138992       0.000008  0.987654     5            NaN   \n",
      "\n",
      "   train_samples_per_second  train_steps_per_second  total_flos  train_loss  \n",
      "0                       NaN                     NaN         NaN         NaN  \n",
      "1                       NaN                     NaN         NaN         NaN  \n",
      "2                       NaN                     NaN         NaN         NaN  \n",
      "3                       NaN                     NaN         NaN         NaN  \n",
      "4                       NaN                     NaN         NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "logs = pd.DataFrame(trainer.state.log_history)\n",
    "print(logs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "C4K19A1p-pf9",
    "outputId": "77f33382-151e-4e17-8aa6-073b352262e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ No hay columna eval_loss en logs\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training points: 24\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# Training Loss\n",
    "# -------------------------\n",
    "train_mask = logs[\"loss\"].notna() & logs[\"step\"].notna()\n",
    "steps_train = logs.loc[train_mask, \"step\"].values\n",
    "loss_train = logs.loc[train_mask, \"loss\"].values\n",
    "\n",
    "# -------------------------\n",
    "# Eval Loss (si existe)\n",
    "# -------------------------\n",
    "if \"eval_loss\" in logs.columns:\n",
    "    eval_mask = logs[\"eval_loss\"].notna() & logs[\"step\"].notna()\n",
    "    steps_eval = logs.loc[eval_mask, \"step\"].values\n",
    "    loss_eval = logs.loc[eval_mask, \"eval_loss\"].values\n",
    "else:\n",
    "    steps_eval, loss_eval = [], []\n",
    "    print(\"âš ï¸ No hay columna eval_loss en logs\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# === TRAINING ===\n",
    "plt.plot(\n",
    "    steps_train, loss_train,\n",
    "    label=\"Training loss\",\n",
    "    linewidth=2.2,\n",
    "    color='#2E86AB',\n",
    "    alpha=0.9,\n",
    "    marker='o',\n",
    "    markersize=4,\n",
    "    markerfacecolor='white',\n",
    "    markeredgewidth=1.2,\n",
    "    markeredgecolor='#2E86AB'\n",
    ")\n",
    "\n",
    "# === EVAL ===\n",
    "if len(steps_eval) > 0:\n",
    "    plt.plot(\n",
    "        steps_eval, loss_eval,\n",
    "        label=\"Eval loss\",\n",
    "        linewidth=2.2,\n",
    "        color='#E74C3C',\n",
    "        alpha=0.9,\n",
    "        marker='s',\n",
    "        markersize=4,\n",
    "        markerfacecolor='white',\n",
    "        markeredgewidth=1.2,\n",
    "        markeredgecolor='#E74C3C'\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"IteraciÃ³n (step)\", fontsize=13, fontweight='bold')\n",
    "plt.ylabel(\"Loss\", fontsize=13, fontweight='bold')\n",
    "plt.title(\"Curva de pÃ©rdida durante el entrenamiento\", fontsize=15, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=12, frameon=True, shadow=True)\n",
    "plt.grid(True, alpha=0.3, linestyle='--', linewidth=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Training points: {len(steps_train)}\")\n",
    "if len(steps_eval) > 0:\n",
    "    print(f\"ğŸ” Eval points: {len(steps_eval)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52pYhjPq-rWZ",
    "outputId": "b0bff9bd-5c0d-4d2c-c66d-0b64f38de291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Guardando localmente en 'gemma_final_adapter'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
      "Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1536,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8960,\n",
      "  \"layer_types\": [\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "chat template saved in gemma_final_adapter/chat_template.jinja\n",
      "tokenizer config file saved in gemma_final_adapter/tokenizer_config.json\n",
      "Special tokens file saved in gemma_final_adapter/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Copiando a Drive en: /content/drive/MyDrive/qwen_models/adapter_v1_A100_BF16_Qwen2.5_2B_KL005_Epoch4 ...\n",
      "âœ… Â¡Ã‰XITO! Tu modelo estÃ¡ seguro en Drive como: adapter_v1_A100_BF16_Qwen2.5_2B_KL005_Epoch4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "# 0. Asegurar que Drive estÃ¡ montado\n",
    "if not os.path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# 1. ConfiguraciÃ³n de nombres\n",
    "LOCAL_PATH = \"gemma_final_adapter\"  # Carpeta temporal en Colab\n",
    "DRIVE_PATH = \"/content/drive/MyDrive/qwen_models\" # Carpeta organizada en tu Drive\n",
    "VERSION = \"v1_A100_BF16_Qwen2.5_2B_KL005_Epoch4\"  # Nombre descriptivo de esta prueba\n",
    "\n",
    "# 2. Guardar Modelo y Tokenizer localmente\n",
    "print(f\"ğŸ’¾ Guardando localmente en '{LOCAL_PATH}'...\")\n",
    "trainer.model.save_pretrained(LOCAL_PATH)\n",
    "tokenizer.save_pretrained(LOCAL_PATH)\n",
    "\n",
    "# 3. Copiar a Google Drive\n",
    "print(f\"ğŸš€ Copiando a Drive en: {DRIVE_PATH}/adapter_{VERSION} ...\")\n",
    "\n",
    "# Crear carpeta en drive si no existe\n",
    "!mkdir -p {DRIVE_PATH}\n",
    "\n",
    "# Copiar recursivamente (-r) la carpeta local a la carpeta versionada en Drive\n",
    "!cp -r {LOCAL_PATH} {DRIVE_PATH}/adapter_{VERSION}\n",
    "\n",
    "print(f\"âœ… Â¡Ã‰XITO! Tu modelo estÃ¡ seguro en Drive como: adapter_{VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3JHiVlc-4KF"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "o2PrJiCm-8Hm",
    "outputId": "8bdd362c-bd5f-42b9-a162-d1fb3ffdc02a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "ğŸ“¥ Cargando modelo base: Qwen/Qwen2.5-1.5B-Instruct...\n"
     ]
    },
    {
     "ename": "PackageNotFoundError",
     "evalue": "No package metadata was found for bitsandbytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfrom_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3642700590.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Usamos la misma config de bits para que sea rÃ¡pido y ligero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m bnb_config = BitsAndBytesConfig(\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mload_in_4bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mbnb_4bit_quant_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nf4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/quantization_config.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load_in_8bit, load_in_4bit, llm_int8_threshold, llm_int8_skip_modules, llm_int8_enable_fp32_cpu_offload, llm_int8_has_fp16_weight, bnb_4bit_compute_dtype, bnb_4bit_quant_type, bnb_4bit_use_double_quant, bnb_4bit_quant_storage, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unused kwargs: {list(kwargs.keys())}. These kwargs are not used in {self.__class__}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/quantization_config.py\u001b[0m in \u001b[0;36mpost_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bnb_4bit_use_double_quant must be a boolean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         if self.load_in_4bit and not version.parse(importlib.metadata.version(\"bitsandbytes\")) >= version.parse(\n\u001b[0m\u001b[1;32m    569\u001b[0m             \u001b[0;34m\"0.39.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         ):\n",
      "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mversion\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;34m\"Version\"\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m     \"\"\"\n\u001b[0;32m--> 889\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mdistribution\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0mthereof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \"\"\"\n\u001b[0;32m--> 862\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfrom_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPackageNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPackageNotFoundError\u001b[0m: No package metadata was found for bitsandbytes",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "# 0. Montar Drive (si no estÃ¡ montado aÃºn)\n",
    "if not os.path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURACIÃ“N\n",
    "# ==========================================\n",
    "BASE_MODEL = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "# âš ï¸ OJO: Reemplaza esto con el nombre exacto de la carpeta que creamos en el paso anterior.\n",
    "# DeberÃ­a ser algo como: .../gemma_models/adapter_v1_A100_BF16...\n",
    "ADAPTER_PATH = \"/content/drive/MyDrive/qwen_models/adapter_v1_A100_BF16_Qwen2.5_2B_KL005_Epoch4\"\n",
    "\n",
    "# ==========================================\n",
    "# 1. CARGAR MODELO BASE\n",
    "# ============================================================================\n",
    "print(f\"ğŸ“¥ Cargando modelo base: {BASE_MODEL}...\")\n",
    "\n",
    "# Usamos la misma config de bits para que sea rÃ¡pido y ligero\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # Mantenemos BFloat16 de la A100\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 2. CARGAR TOKENIZER\n",
    "# ============================================================================\n",
    "# Intentamos cargar el tokenizer desde el adapter (si lo guardaste), sino del base\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ADAPTER_PATH)\n",
    "except:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ==========================================\n",
    "# 3. INYECTAR EL LORA (PEFT)\n",
    "# ============================================================================\n",
    "print(f\"ğŸ”— Fusionando adaptador desde: {ADAPTER_PATH}...\")\n",
    "model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)\n",
    "\n",
    "# Poner en modo evaluaciÃ³n para probar\n",
    "model.eval()\n",
    "\n",
    "print(\"âœ… Â¡Modelo cargado exitosamente!\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. PRUEBA RÃPIDA\n",
    "# ============================================================================\n",
    "prompt = \"Input abstract: The feline consumed the rodent. Output PLS:\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,\n",
    "        use_cache=True,\n",
    "        do_sample=True,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "print(\"\\nğŸ¤– Resultado:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_E8GYFQg_ZS_",
    "outputId": "a19022d1-572b-44cd-8d4f-ed15828e386e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¤– Resultado Qwen:\n",
      "Plain Title:\n",
      "Feline Rodent Consumption Study\n",
      "\n",
      "Rationale:\n",
      "Background: Felines are naturally curious animals who often consume small rodents as prey. This curiosity can lead to accidental ingestion of harmful substances if the cat's sense of smell is compromised due to illness or other factors. Understanding the behavior of cats towards rodents is crucial for preventing accidents and ensuring the safety of both pets and humans in households where cats live. The study aims to investigate how cats perceive and react to different odors associated with rodents, particularly focusing on the role of olfactory cues and the impact of human intervention during feeding sessions.\n",
      "\n",
      "Trial Design:\n",
      "This study involves observing feline reactions to various odors emitted by rats while the rats are placed inside a transparent container. The researchers monitor the cats' responses through video cameras positioned at strategic angles to capture detailed facial expressions and body language. Cats are exposed to different types of rat odors, including those produced by rats eating, urinating, and defecating, along with control conditions without odors. The experiment runs over several days, with each exposure session lasting approximately 30 minutes. Researchers measure the frequency and intensity of the cats' reactions based on predefined criteria, aiming to quantify the likelihood of a reaction in response to each odor type. Data collection continues until the cats exhibit a significant number of reactions across all odor categories.\n",
      "\n",
      "Results:\n",
      "Key findings suggest that cats show significantly increased interest and engagement when exposed to the scent of rodents compared to the absence of odors. Specifically, the study indicates that cats are more likely to approach, sniff, and potentially even eat food items near areas where they detect rat odors. These observations indicate that cats possess a strong innate attraction to rodents, driven primarily by the presence of their scent. Furthermore, the study highlights that the timing and duration of the exposure play a critical role in triggering the cat's olfactory response. For instance, cats showed higher levels of activity within 15 minutes after being introduced to the odor, suggesting that short-term exposure might be sufficient to elicit a behavioral reaction. The research concludes that understanding the specific odors released by rodents could help in developing targeted interventions to prevent unintentional consumption by cats.\n",
      "\n",
      "Conclusions:\n",
      "The study underscores the importance of considering catsâ€™ olfactory preferences in managing household environments. It also emphasizes the need for further investigation into the long-term effects of environmental modifications aimed at reducing the risk of feline rodent consumption. Future studies could explore the use of artificial odors mimicking those produced by rats to create deterrents for cats in pet-friendly spaces.\n"
     ]
    }
   ],
   "source": [
    "# 1. El mismo template gigante que usaste en el entrenamiento\n",
    "INSTR_PROMPT = \"\"\"Using the following abstract of a biomedical study as input, generate a Plain Language Summary\n",
    "(PLS) understandable by any patient, regardless of their health literacy. Ensure that the generated text\n",
    "adheres to the following instructions which should be followed step-by-step:\n",
    "a. Specific Structure: The generated PLS should be presented in a logical order, using the following\n",
    "order:\n",
    "1. Plain Title\n",
    "2. Rationale\n",
    "3. Trial Design\n",
    "4. Results\n",
    "b. Sections should be authored following these parameters:\n",
    "1. Plain Title: Simplified title understandable to a layperson that summarizes the research that was\n",
    "done.\n",
    "2. Rationale: Include: background or study rationale providing a general description of the\n",
    "condition, what it may cause or why it is a burden for the patients; the reason and main hypothesis\n",
    "for the study; and why the study is needed, and why the study medication has the potential to\n",
    "treat the condition.\n",
    "3. Trial Design: Answer â€˜How is this study designed?â€™ Include the description of the design,\n",
    "description of study and patient population (age, health condition, gender), and the expected\n",
    "amount of time a person will be in the study.\n",
    "4. Results: Answer â€˜What were the main results of the studyâ€™, include the benefits for the patients,\n",
    "how the study was relevant for the area of study, and the conclusions from the investigator.\n",
    "c. Consistency and Replicability: The generated PLS should be consistent regardless of the order of\n",
    "sentences or the specific phrasing used in the input protocol text.\n",
    "d. Compliance with Plain Language Guidelines: The generated PLS must follow all these plain\n",
    "language guidelines:\n",
    "â€¢ Have readability grade level of 6 or below.\n",
    "â€¢ Do not have jargon. All technical or medical words or terms should be defined or broken down\n",
    "into simple and logical explanations.\n",
    "â€¢ Active voice, not passive.\n",
    "â€¢ Mostly one or two syllable words.\n",
    "â€¢ Sentences of 15 words or less.\n",
    "â€¢ Short paragraphs of 3-5 sentences.\n",
    "â€¢ Simple numbers (e.g., ratios, no percentages).\n",
    "e. Do not invent Content: The AI model should not invent information. If the AI model includes data\n",
    "other than the one given in the input abstract, the AI model should guarantee such data is verified and\n",
    "real.\n",
    "f. Aim for an approximate PLS length of 500-900 words.\n",
    "\n",
    "Input abstract:\n",
    "\n",
    "{source}\n",
    "\n",
    "Output PLS:\n",
    "\"\"\"\n",
    "\n",
    "# 2. Tu texto de prueba\n",
    "test_abstract = \"The feline consumed the rodent.\"\n",
    "\n",
    "# 3. Construir el prompt real\n",
    "full_prompt = INSTR_PROMPT.format(source=test_abstract)\n",
    "\n",
    "# 4. Inferencia\n",
    "inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        use_cache=True,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9\n",
    "    )\n",
    "\n",
    "print(\"\\nğŸ¤– Resultado Qwen:\")\n",
    "# Decodificamos cortando la entrada para ver solo la respuesta\n",
    "print(tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Bmp7nSPAdIh",
    "outputId": "ec4556d8-3fd5-4eaf-8d2a-76d14e4078c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prompt', 'response']\n",
      "Index(['prompt', 'response'], dtype='object')\n",
      "                                              source  \\\n",
      "0  Background\\nPeriodic fever, aphthous stomatiti...   \n",
      "1  Background\\nMemory problems are a common cogni...   \n",
      "\n",
      "                                            response  \n",
      "0  Tonsillectomy for PFAPA syndrome (a rare cause...  \n",
      "1  Cognitive rehabilitation for memory deficits a...  \n"
     ]
    }
   ],
   "source": [
    "print(hf_ds[\"test\"].column_names)\n",
    "df_test = hf_ds[\"test\"].to_pandas()\n",
    "print(df_test.columns)\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_source_from_prompt(prompt):\n",
    "    \"\"\"\n",
    "    Extrae el texto entre 'original text' y 'simplified text' del prompt.\n",
    "    Robusto ante espacios, mayÃºsculas y saltos de lÃ­nea.\n",
    "    \"\"\"\n",
    "    match = re.search(\n",
    "        r\"Input abstract:\\s*[:\\-â€“]?\\s*(.*?)\\s*Output PLS\",\n",
    "        prompt,\n",
    "        re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return \"\"\n",
    "\n",
    "# Crear columna 'source' desde 'prompt'\n",
    "df_test[\"source\"] = df_test[\"prompt\"].apply(extract_source_from_prompt)\n",
    "\n",
    "# Mantener solo columnas necesarias\n",
    "df_test = df_test[[\"source\", \"response\"]]\n",
    "\n",
    "# Mostrar ejemplo de verificaciÃ³n\n",
    "print(df_test.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blsBvHE1BhuF"
   },
   "outputs": [],
   "source": [
    "if \"trainer\" in locals() and hasattr(trainer, \"model\"):\n",
    "    fine_tuned_model = trainer.model.eval()\n",
    "else:\n",
    "    fine_tuned_model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfKfY4qxBkOK"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "import pandas as pd\n",
    "\n",
    "def generate_simplifications_v2(\n",
    "    df: pd.DataFrame,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    instr_prompt: str,\n",
    "    batch_size: int = 4,  # Subido a 4 para A100 (puedes bajar a 2 si hay OOM)\n",
    "    max_source_tokens: int = 1024, # Aumentado para aprovechar contexto de Gemma\n",
    "    sim_threshold: float = 0.75,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Genera textos simplificados con estrategia de recuperaciÃ³n (Fallback).\n",
    "    1. Intenta generaciÃ³n estÃ¡ndar (L1).\n",
    "    2. Si sale vacÃ­o -> Reintenta con temperatura alta (L2) o Beam Search (L3).\n",
    "    3. Si es una copia del input -> Reintenta para forzar parÃ¡frasis.\n",
    "    \"\"\"\n",
    "\n",
    "    # ConfiguraciÃ³n del Tokenizer para generaciÃ³n\n",
    "    tokenizer.padding_side = \"left\" # IMPORTANTE: Para generaciÃ³n batched, left padding es mejor\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.clean_up_tokenization_spaces = True\n",
    "\n",
    "    # ConfiguraciÃ³n del Modelo\n",
    "    model.eval()\n",
    "    model.config.use_cache = True\n",
    "\n",
    "    # Limpieza inicial\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nğŸš€ GeneraciÃ³n iniciada (Modo Seguro A100)...\")\n",
    "\n",
    "    # === FUNCIONES AUXILIARES INTERNAS ===\n",
    "\n",
    "    def truncate_text(text, max_tokens=max_source_tokens):\n",
    "        \"\"\"Corta el texto del centro si es demasiado largo para el prompt.\"\"\"\n",
    "        tokens = text.split() # AproximaciÃ³n rÃ¡pida por espacios\n",
    "        if len(tokens) <= max_tokens:\n",
    "            return text\n",
    "        head = tokens[:max_tokens // 2]\n",
    "        tail = tokens[-max_tokens // 2:]\n",
    "        return \" \".join(head + [\"[...]\"] + tail)\n",
    "\n",
    "    def safe_generate(prompts, gen_params):\n",
    "        \"\"\"Genera sin calcular gradientes.\"\"\"\n",
    "        inputs = tokenizer(\n",
    "            prompts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=2048 # Contexto total permitido\n",
    "        ).to(model.device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            outputs = model.generate(**inputs, **gen_params)\n",
    "\n",
    "        # Decodificar solo los nuevos tokens generados (cortando el prompt de entrada)\n",
    "        # Nota: model.generate devuelve input + output. Cortamos el input.\n",
    "        input_len = inputs.input_ids.shape[1]\n",
    "        generated_tokens = outputs[:, input_len:]\n",
    "\n",
    "        texts = tokenizer.batch_decode(\n",
    "            generated_tokens,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True\n",
    "        )\n",
    "        return texts\n",
    "\n",
    "    def extract_simplified_text(text):\n",
    "        \"\"\"Limpia el texto generado.\"\"\"\n",
    "        # Si el modelo repite el prompt, intentamos buscar la etiqueta de salida\n",
    "        match = re.search(r\"Output PLS\\s*[:\\-â€“]?\\s*(.*)\", text, re.IGNORECASE | re.DOTALL)\n",
    "        if match:\n",
    "            simplified = match.group(1).strip()\n",
    "        else:\n",
    "            simplified = text.strip()\n",
    "\n",
    "        # Limpieza extra de artefactos\n",
    "        simplified = re.sub(r\"<\\|endoftext\\|>\", \"\", simplified)\n",
    "        simplified = re.sub(r\"\\s+\", \" \", simplified).strip()\n",
    "        return simplified\n",
    "\n",
    "    # === PARÃMETROS DE GENERACIÃ“N (Niveles de Creatividad) ===\n",
    "\n",
    "    # L1: EstÃ¡ndar (Conservador)\n",
    "    GEN_PARAMS_L1 = {\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 0.6,\n",
    "        \"top_p\": 0.9,\n",
    "        \"do_sample\": True,\n",
    "        \"repetition_penalty\": 1.1,\n",
    "        \"eos_token_id\": tokenizer.eos_token_id,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id\n",
    "    }\n",
    "\n",
    "    # L2: Creativo (Para romper bloqueos/vacÃ­os)\n",
    "    GEN_PARAMS_L2 = {\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 1.2,\n",
    "        \"top_p\": 0.95,\n",
    "        \"do_sample\": True,\n",
    "        \"repetition_penalty\": 1.0, # Sin penalizaciÃ³n para fluidez\n",
    "        \"eos_token_id\": tokenizer.eos_token_id,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id\n",
    "    }\n",
    "\n",
    "    # L3: Beam Search (BÃºsqueda exhaustiva, mÃ¡s lento)\n",
    "    GEN_PARAMS_L3 = {\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"num_beams\": 3,\n",
    "        \"do_sample\": False,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "        \"eos_token_id\": tokenizer.eos_token_id,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id\n",
    "    }\n",
    "\n",
    "    # === PREPARACIÃ“N DATOS ===\n",
    "    df = df.copy()\n",
    "    # Aseguramos que la columna source existe\n",
    "    if \"source\" not in df.columns:\n",
    "        raise ValueError(\"El DataFrame debe tener una columna llamada 'source'\")\n",
    "\n",
    "    df[\"source_for_generation\"] = df[\"source\"].apply(lambda x: truncate_text(str(x)))\n",
    "\n",
    "    # === BUCLE PRINCIPAL ===\n",
    "    generated_texts = []\n",
    "    is_copy_list = []\n",
    "    was_regenerated_list = []\n",
    "    regeneration_level_list = []\n",
    "    similarity_scores = []\n",
    "\n",
    "    # Iterar por lotes\n",
    "    for i in tqdm(range(0, len(df), batch_size), desc=\"Generando...\"):\n",
    "        # Limpieza de memoria periÃ³dica\n",
    "        if i % 20 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        # Preparar lote\n",
    "        batch_sources = df[\"source\"].iloc[i:i+batch_size].tolist()\n",
    "        batch_trunc = df[\"source_for_generation\"].iloc[i:i+batch_size].tolist()\n",
    "\n",
    "        # Formatear con el Prompt Maestro\n",
    "        batch_prompts = [instr_prompt.format(source=s) for s in batch_trunc]\n",
    "\n",
    "        # 1. INTENTO L1 (EstÃ¡ndar)\n",
    "        full_texts = safe_generate(batch_prompts, GEN_PARAMS_L1)\n",
    "\n",
    "        for j, raw_text in enumerate(full_texts):\n",
    "            simplified = extract_simplified_text(raw_text)\n",
    "            original_text = batch_sources[j]\n",
    "\n",
    "            # Variables de estado\n",
    "            regen_level = 0\n",
    "\n",
    "            # 2. VERIFICACIÃ“N: Â¿ESTÃ VACÃO?\n",
    "            if not simplified or len(simplified.strip()) < 10:\n",
    "                if verbose:\n",
    "                    print(f\"âš ï¸ VacÃ­o detectado (Idx {i+j}). Reintentando L2...\")\n",
    "\n",
    "                # Reintento L2 (Alta temperatura)\n",
    "                prompt_single = [batch_prompts[j]]\n",
    "                regen_text = safe_generate(prompt_single, GEN_PARAMS_L2)[0]\n",
    "                simplified = extract_simplified_text(regen_text)\n",
    "                regen_level = 2\n",
    "\n",
    "                # Si sigue vacÃ­o, Reintento L3 (Beam Search)\n",
    "                if not simplified or len(simplified.strip()) < 10:\n",
    "                    regen_text = safe_generate(prompt_single, GEN_PARAMS_L3)[0]\n",
    "                    simplified = extract_simplified_text(regen_text)\n",
    "                    regen_level = 3\n",
    "\n",
    "            # 3. VERIFICACIÃ“N: Â¿ES UNA COPIA? (Similitud)\n",
    "            sim = SequenceMatcher(None, original_text.lower(), simplified.lower()).ratio()\n",
    "            is_copy = sim > sim_threshold\n",
    "\n",
    "            if is_copy:\n",
    "                if verbose and regen_level == 0:\n",
    "                    print(f\"âš ï¸ Copia detectada (Sim: {sim:.2f}). Reintentando L2...\")\n",
    "\n",
    "                prompt_single = [batch_prompts[j]]\n",
    "                # Forzamos regeneraciÃ³n creativa\n",
    "                regen_text = safe_generate(prompt_single, GEN_PARAMS_L2)[0]\n",
    "                simplified_regen = extract_simplified_text(regen_text)\n",
    "                sim_regen = SequenceMatcher(None, original_text.lower(), simplified_regen.lower()).ratio()\n",
    "\n",
    "                # Si mejorÃ³ (menos similitud), nos quedamos con el nuevo\n",
    "                if sim_regen < sim:\n",
    "                    simplified = simplified_regen\n",
    "                    sim = sim_regen\n",
    "                    is_copy = sim > sim_threshold\n",
    "                    regen_level = 2\n",
    "\n",
    "            # Guardar resultados\n",
    "            generated_texts.append(simplified)\n",
    "            is_copy_list.append(is_copy)\n",
    "            was_regenerated_list.append(regen_level > 0)\n",
    "            regeneration_level_list.append(regen_level)\n",
    "            similarity_scores.append(sim)\n",
    "\n",
    "    # === ASIGNAR AL DATAFRAME ===\n",
    "    df[\"generated_text\"] = generated_texts\n",
    "    df[\"is_copy\"] = is_copy_list\n",
    "    df[\"was_regenerated\"] = was_regenerated_list\n",
    "    df[\"regeneration_level\"] = regeneration_level_list\n",
    "    df[\"similarity_score\"] = similarity_scores\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nâœ… Proceso finalizado.\")\n",
    "        print(f\"ğŸ“Š MÃ©tricas: Regenerados={sum(was_regenerated_list)} | Copias restantes={sum(is_copy_list)}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dolrAdBJBtEl",
    "outputId": "801c86b5-d060-4c42-eeed-e2727ea8422b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                source  \\\n",
      "95   Background\\nThis updated Cochrane Review of re...   \n",
      "15   Background\\nIn many countries emergency depart...   \n",
      "30   Background\\nPsychotherapy is regarded as the f...   \n",
      "158  Background\\nSpina bifida is a fetal neural tub...   \n",
      "128  We included 12 trials in the original review (...   \n",
      "\n",
      "                                              response  \n",
      "95   Reminiscence therapy for dementia\\nReview ques...  \n",
      "15   Primary care professionals providing nonâ€urgen...  \n",
      "30   Psychological therapies for borderline persona...  \n",
      "158  Spina bifida repair and infant and maternal he...  \n",
      "128  Transcutaneous Electrical Nerve Stimulation (T...  \n",
      "50\n"
     ]
    }
   ],
   "source": [
    "df_test50= df_test.sample(n=50, random_state=42)\n",
    "\n",
    "print(df_test50.head())\n",
    "print(len(df_test50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DppBKaR2BvH3",
    "outputId": "b0b537c7-88f8-48e7-e049-cc471d56c17a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ GeneraciÃ³n iniciada (Modo Seguro A100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [29:31<00:00, 70.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Proceso finalizado.\n",
      "ğŸ“Š MÃ©tricas: Regenerados=0 | Copias restantes=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_out = generate_simplifications_v2(\n",
    "    df=df_test50,\n",
    "    model=fine_tuned_model,\n",
    "    tokenizer=tokenizer,\n",
    "    instr_prompt=INSTR_PROMPT,\n",
    "    batch_size=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHJ-QrF4Bwvf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "034a43c5d434418f9615a69faa4a7f32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bd39def12140423b96e8b9affc0473aa",
       "IPY_MODEL_7f8e3653bd594e9592357673ccd9f0aa",
       "IPY_MODEL_be154edc013f4e5d873fd0f4753d6077"
      ],
      "layout": "IPY_MODEL_d675650999a94c4db2aadc2fe5b50c11"
     }
    },
    "056adfcfb0574e4baa63f98dbd2f1120": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08453c901efe461b878a122f0b917a7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f3b1125f89a4770927912fa23125d31",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f4911d3c01bd4025bd4ea35edd81a44f",
      "value": "â€‡242/242â€‡[00:00&lt;00:00,â€‡30.9kB/s]"
     }
    },
    "0a9a18caf5664c6f8cca412c5dbe6338": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0c2e8b4468c54b38a0f8ce9c666ac009": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dae673b3ea04a11bce5efea3b3cce3f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f9a3ed0ec1d441fa87614c3e69cd1ab",
      "value": 1
     }
    },
    "10c2184e66b944eba8a92fc85c86156f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "1dae673b3ea04a11bce5efea3b3cce3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "259d0c5876f44edf8564ef5619a42c29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2f6728b05dd94d249c79743d7eb5f0b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e853212b84f54c988894208eba82db2e",
       "IPY_MODEL_9fda0c02cfbb47e7aa0d01105f75c96a",
       "IPY_MODEL_9f3c29bb6474429795308334add66244"
      ],
      "layout": "IPY_MODEL_d226fb147f554c66827793af4a8c5024"
     }
    },
    "2f9a3ed0ec1d441fa87614c3e69cd1ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "37d99fa14016472591c52afde0d1763f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c5421a232ee41908680fdbae51fff21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c568d3ca9fc4146808627d289759d2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f7bf3a1ab8b4d4e96d0677382c98418": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab746e1122924a8baeb042cab61c10c2",
       "IPY_MODEL_ae3deacd7aa847c3bf93e3528c4ad1af",
       "IPY_MODEL_57b014f559184e0c900981e211dec9cb"
      ],
      "layout": "IPY_MODEL_aee0ca91cf074ae0ba7a792a8df68c96"
     }
    },
    "4161910787b043428f2ce953dd866900": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4932a2f8676141a98381938e12b67aad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9da4d26eb9ea4c138ebe3396bb64a0c6",
       "IPY_MODEL_c13db08f76f8411490911da5fc53d588",
       "IPY_MODEL_7d8b8c1787034d8e8b77e9c13ea6570e"
      ],
      "layout": "IPY_MODEL_a0e6f63ea71b4ddfbbdb89e852e7184a"
     }
    },
    "50438ecfdc4f4b71a7ea389d2839f43e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_99417e3f6c80483c8eadec04e190fcd0",
       "IPY_MODEL_0c2e8b4468c54b38a0f8ce9c666ac009",
       "IPY_MODEL_6000ed00cda94390855749b99295e5d6"
      ],
      "layout": "IPY_MODEL_850b6ba459344cb0980a1b974dec3828"
     }
    },
    "50e25e44abf04f1ca178adcd4503c769": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5537304b6d8744cc802c2384807f56b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c119c23995a04272b83597228a74bd13",
       "IPY_MODEL_9c550998c3ce47babbda9d0f2bb6b945",
       "IPY_MODEL_08453c901efe461b878a122f0b917a7b"
      ],
      "layout": "IPY_MODEL_d7507b1ad96e43468d250626fcbc1c3c"
     }
    },
    "57b014f559184e0c900981e211dec9cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_741eef0f3c3f469db58c5363893eb737",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f7cdca9d226b4bcc869d827a651593db",
      "value": "â€‡1.67M/?â€‡[00:00&lt;00:00,â€‡638kB/s]"
     }
    },
    "5cac331a544947efb6e69cf43755b507": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f3b1125f89a4770927912fa23125d31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6000ed00cda94390855749b99295e5d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b615befe1b9c43939267e6dc7842bf59",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0a9a18caf5664c6f8cca412c5dbe6338",
      "value": "â€‡7.30k/?â€‡[00:00&lt;00:00,â€‡601kB/s]"
     }
    },
    "6ab86f8b096e49f295c010ec103b37f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "741eef0f3c3f469db58c5363893eb737": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d8b8c1787034d8e8b77e9c13ea6570e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ab86f8b096e49f295c010ec103b37f9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d0ef656d704240fc80e53fac9fef6c41",
      "value": "â€‡2.78M/?â€‡[00:00&lt;00:00,â€‡6.07MB/s]"
     }
    },
    "7f8e3653bd594e9592357673ccd9f0aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3b0a7b7384643ed81b38fa6f63c7341",
      "max": 162,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e81c82a29f0d46b080120e633acbf027",
      "value": 162
     }
    },
    "83518bb99aa84f63b9f0ffdbe3c818ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "850b6ba459344cb0980a1b974dec3828": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cb746ccb60844358a0820283c829553": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5da069cb60143bc99707792098e87fe",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_adcbeb5dd91a466790402f3159a8bb61",
      "value": "tokenizer.json:â€‡"
     }
    },
    "9026b1dc4e374cb3a4fbd8d141582013": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "98ebe9b69e944d0bbbae38ce9f312339": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99417e3f6c80483c8eadec04e190fcd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a360471cb2ec4b6a90f450803c951872",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3c568d3ca9fc4146808627d289759d2b",
      "value": "tokenizer_config.json:â€‡"
     }
    },
    "9c550998c3ce47babbda9d0f2bb6b945": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37d99fa14016472591c52afde0d1763f",
      "max": 242,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_abff7e6737cf4d6b8d499cd063324811",
      "value": 242
     }
    },
    "9da4d26eb9ea4c138ebe3396bb64a0c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b295d53087d942b48d65419ab989fe42",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_056adfcfb0574e4baa63f98dbd2f1120",
      "value": "vocab.json:â€‡"
     }
    },
    "9f3c29bb6474429795308334add66244": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a331cbbcc6be4c21852dfcf573aa6a48",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e176652fc1b5491e9ae36c747927dd3a",
      "value": "â€‡1800/1800â€‡[00:09&lt;00:00,â€‡181.64â€‡examples/s]"
     }
    },
    "9fda0c02cfbb47e7aa0d01105f75c96a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6481e51b18a44f4a99296224973003d",
      "max": 1800,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c48aeb916746424cbf2ea98c67f526bb",
      "value": 1800
     }
    },
    "a0e6f63ea71b4ddfbbdb89e852e7184a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a180900ff1a047a1984b63413b96d52c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a331cbbcc6be4c21852dfcf573aa6a48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a360471cb2ec4b6a90f450803c951872": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a39ec16f891740099d32e247922a85b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "a9fa8771c4d64863a02f2f35fbbcd8ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab746e1122924a8baeb042cab61c10c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c5421a232ee41908680fdbae51fff21",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_50e25e44abf04f1ca178adcd4503c769",
      "value": "merges.txt:â€‡"
     }
    },
    "abff7e6737cf4d6b8d499cd063324811": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "adcbeb5dd91a466790402f3159a8bb61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae3deacd7aa847c3bf93e3528c4ad1af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a39ec16f891740099d32e247922a85b9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b28b0e600ef44bbbbc9d49241c5f9eef",
      "value": 1
     }
    },
    "ae69ad33d94140808c576f5091ebb3e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aee0ca91cf074ae0ba7a792a8df68c96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af9553b10b5745b992be72cbc703575b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b28b0e600ef44bbbbc9d49241c5f9eef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b295d53087d942b48d65419ab989fe42": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3b0a7b7384643ed81b38fa6f63c7341": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4a45082faa141b9a5978035295f4480": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b615befe1b9c43939267e6dc7842bf59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b955ee8ccf8747bd87a07cfbc261b247": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb8ad40844a1421b8a67e22b6830ab06": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd39def12140423b96e8b9affc0473aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b955ee8ccf8747bd87a07cfbc261b247",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a9fa8771c4d64863a02f2f35fbbcd8ca",
      "value": "Filter:â€‡100%"
     }
    },
    "be154edc013f4e5d873fd0f4753d6077": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83518bb99aa84f63b9f0ffdbe3c818ae",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ae69ad33d94140808c576f5091ebb3e3",
      "value": "â€‡162/162â€‡[00:00&lt;00:00,â€‡745.00â€‡examples/s]"
     }
    },
    "c119c23995a04272b83597228a74bd13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4161910787b043428f2ce953dd866900",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_af9553b10b5745b992be72cbc703575b",
      "value": "generation_config.json:â€‡100%"
     }
    },
    "c13db08f76f8411490911da5fc53d588": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10c2184e66b944eba8a92fc85c86156f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a180900ff1a047a1984b63413b96d52c",
      "value": 1
     }
    },
    "c48aeb916746424cbf2ea98c67f526bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c6481e51b18a44f4a99296224973003d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0ef656d704240fc80e53fac9fef6c41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d226fb147f554c66827793af4a8c5024": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d675650999a94c4db2aadc2fe5b50c11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7507b1ad96e43468d250626fcbc1c3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db48c6119c3646e79809acdf393de949": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9026b1dc4e374cb3a4fbd8d141582013",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_259d0c5876f44edf8564ef5619a42c29",
      "value": 1
     }
    },
    "df7a6db0696748869888fe72d8b77a0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8cb746ccb60844358a0820283c829553",
       "IPY_MODEL_db48c6119c3646e79809acdf393de949",
       "IPY_MODEL_ff86e1210ed14cf1a5e0d983db8c92d5"
      ],
      "layout": "IPY_MODEL_b4a45082faa141b9a5978035295f4480"
     }
    },
    "e176652fc1b5491e9ae36c747927dd3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e81c82a29f0d46b080120e633acbf027": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e853212b84f54c988894208eba82db2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98ebe9b69e944d0bbbae38ce9f312339",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_edf0a59d523741d7956b2b47eb94016f",
      "value": "Map:â€‡100%"
     }
    },
    "edf0a59d523741d7956b2b47eb94016f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4911d3c01bd4025bd4ea35edd81a44f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5da069cb60143bc99707792098e87fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7cdca9d226b4bcc869d827a651593db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff86e1210ed14cf1a5e0d983db8c92d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb8ad40844a1421b8a67e22b6830ab06",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5cac331a544947efb6e69cf43755b507",
      "value": "â€‡7.03M/?â€‡[00:00&lt;00:00,â€‡20.1MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
